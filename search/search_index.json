{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AI Blogger (Inker)","text":"<p>A LangChain-based automated daily AI blogger that discovers new software-engineering news, generates draft blog posts, scores them, refines the winner, and outputs a final Markdown blog post.</p>"},{"location":"#overview","title":"Overview","text":"<p>AI Blogger (Inker) is designed for simple CLI execution and cron automation. It leverages multiple news sources and AI-powered content generation to produce high-quality technical blog posts.</p> <pre><code>flowchart LR\n    subgraph Sources[\"News Sources\"]\n        HN[Hacker News]\n        WS[Web Search]\n        YT[YouTube]\n    end\n\n    subgraph Pipeline[\"Content Pipeline\"]\n        F[Fetch Articles]\n        G[Generate Candidates]\n        S[Score &amp; Rank]\n        R[Refine Winner]\n    end\n\n    subgraph Output[\"Output\"]\n        MD[Markdown Post]\n    end\n\n    Sources --&gt; F\n    F --&gt; G\n    G --&gt; S\n    S --&gt; R\n    R --&gt; MD</code></pre>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Modular, extensible architecture for easy addition of new sources</li> <li>Multi-source news fetching from Hacker News, Tavily web search, and YouTube</li> <li>Dynamic source selection via CLI</li> <li>AI-powered content generation using LangChain and GPT-4</li> <li>Automated scoring and selection of best content</li> <li>Markdown output ready for publishing</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"Resource Description Getting Started Installation and quick start guide Architecture System design and component overview Developer Guide Extending and customizing AI Blogger API Reference Module and function documentation Operations Deployment, monitoring, and troubleshooting Contributing How to contribute to the project"},{"location":"#requirements","title":"Requirements","text":"<ul> <li>Python 3.9+</li> <li>OpenAI API key (required)</li> <li>Tavily API key (optional, for web search)</li> <li>YouTube API key (optional, for YouTube trending)</li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE for details.</p>"},{"location":"api-reference/","title":"API Reference","text":"<p>This document provides detailed documentation for the AI Blogger (Inker) Python modules and their public interfaces.</p>"},{"location":"api-reference/#module-overview","title":"Module Overview","text":"<pre><code>flowchart TB\n    subgraph Main[\"ai_blogger\"]\n        INIT[__init__.py]\n        MAIN[__main__.py]\n    end\n\n    subgraph Core[\"Core Modules\"]\n        FETCH[fetchers.py]\n        CHAINS[chains.py]\n        MODELS[models.py]\n        CONFIG[config.py]\n        UTILS[utils.py]\n    end\n\n    INIT --&gt; FETCH &amp; CHAINS &amp; MODELS &amp; CONFIG &amp; UTILS\n    MAIN --&gt; INIT</code></pre>"},{"location":"api-reference/#ai_bloggermodels","title":"ai_blogger.models","text":"<p>Pydantic data models for the application.</p>"},{"location":"api-reference/#article","title":"Article","text":"<p>Represents a news article or video from various sources.</p> <pre><code>class Article(BaseModel):\n    title: str\n    url: HttpUrl\n    source: str\n    summary: str\n    topic: str\n    thumbnail: Optional[str] = None\n</code></pre> <p>Attributes:</p> Attribute Type Description <code>title</code> str Article title <code>url</code> HttpUrl Article URL <code>source</code> str Source identifier (e.g., \"hacker_news\", \"youtube\") <code>summary</code> str Article summary or description <code>topic</code> str Topic the article was fetched for <code>thumbnail</code> Optional[str] Thumbnail URL (for videos) <p>Example:</p> <pre><code>from ai_blogger.models import Article\n\narticle = Article(\n    title=\"New AI Framework Released\",\n    url=\"https://example.com/article\",\n    source=\"hacker_news\",\n    summary=\"A new AI framework...\",\n    topic=\"AI software engineering\",\n)\n</code></pre>"},{"location":"api-reference/#candidatepost","title":"CandidatePost","text":"<p>Represents a draft blog post candidate.</p> <pre><code>class CandidatePost(BaseModel):\n    title: str\n    content: str\n    sources: List[str]\n    topic: str\n</code></pre> <p>Attributes:</p> Attribute Type Description <code>title</code> str Blog post title <code>content</code> str Full blog post content <code>sources</code> List[str] URLs of source articles used <code>topic</code> str Primary topic of the post"},{"location":"api-reference/#postscore","title":"PostScore","text":"<p>Scoring breakdown for a candidate post.</p> <pre><code>class PostScore(BaseModel):\n    relevance: float\n    originality: float\n    depth: float\n    clarity: float\n    engagement: float\n    total: float\n    reasoning: str\n</code></pre> <p>Attributes:</p> Attribute Type Description <code>relevance</code> float Relevance score (0-10) <code>originality</code> float Originality score (0-10) <code>depth</code> float Depth score (0-10) <code>clarity</code> float Clarity score (0-10) <code>engagement</code> float Engagement score (0-10) <code>total</code> float Weighted total score <code>reasoning</code> str Explanation of the scores"},{"location":"api-reference/#scoredpost","title":"ScoredPost","text":"<p>A candidate post with its score.</p> <pre><code>class ScoredPost(BaseModel):\n    candidate: CandidatePost\n    score: PostScore\n</code></pre>"},{"location":"api-reference/#ai_bloggerfetchers","title":"ai_blogger.fetchers","text":"<p>Modular fetcher architecture for news sources.</p>"},{"location":"api-reference/#basefetcher","title":"BaseFetcher","text":"<p>Abstract base class for all fetchers.</p> <pre><code>class BaseFetcher(ABC):\n    name: str = \"\"\n    env_key: Optional[str] = None\n    description: str = \"\"\n\n    def is_available(self) -&gt; bool: ...\n    def get_missing_key_message(self) -&gt; str: ...\n    def _validate_inputs(self, topic: str, max_results: int) -&gt; None: ...\n\n    @abstractmethod\n    def fetch(self, topic: str, max_results: int) -&gt; List[Article]: ...\n</code></pre> <p>Methods:</p>"},{"location":"api-reference/#is_available","title":"is_available()","text":"<p>Check if this fetcher is available (has required API key).</p> <pre><code>def is_available(self) -&gt; bool\n</code></pre> <p>Returns: <code>True</code> if fetcher can be used, <code>False</code> otherwise.</p>"},{"location":"api-reference/#fetch","title":"fetch()","text":"<p>Fetch articles for a given topic.</p> <pre><code>@abstractmethod\ndef fetch(self, topic: str, max_results: int) -&gt; List[Article]\n</code></pre> <p>Args:</p> <ul> <li><code>topic</code> (str): The topic to search for (must not be empty)</li> <li><code>max_results</code> (int): Maximum number of results (must be positive)</li> </ul> <p>Returns: List of <code>Article</code> objects.</p> <p>Raises: <code>ValueError</code> if inputs are invalid.</p>"},{"location":"api-reference/#hackernewsfetcher","title":"HackerNewsFetcher","text":"<p>Fetcher for Hacker News articles via Algolia API.</p> <pre><code>@register_fetcher(\"hacker_news\")\nclass HackerNewsFetcher(BaseFetcher):\n    name = \"hacker_news\"\n    env_key = None\n    description = \"Fetch articles from Hacker News\"\n</code></pre> <p>No API key required.</p>"},{"location":"api-reference/#websearchfetcher","title":"WebSearchFetcher","text":"<p>Fetcher for web search results via Tavily API.</p> <pre><code>@register_fetcher(\"web\")\nclass WebSearchFetcher(BaseFetcher):\n    name = \"web\"\n    env_key = \"TAVILY_API_KEY\"\n    description = \"Fetch articles from web search (Tavily)\"\n</code></pre> <p>Requires <code>TAVILY_API_KEY</code> environment variable.</p>"},{"location":"api-reference/#youtubefetcher","title":"YouTubeFetcher","text":"<p>Fetcher for trending YouTube videos via YouTube Data API v3.</p> <pre><code>@register_fetcher(\"youtube\")\nclass YouTubeFetcher(BaseFetcher):\n    name = \"youtube\"\n    env_key = \"YOUTUBE_API_KEY\"\n    description = \"Fetch trending YouTube videos\"\n</code></pre> <p>Requires <code>YOUTUBE_API_KEY</code> environment variable.</p>"},{"location":"api-reference/#register_fetcher","title":"register_fetcher()","text":"<p>Decorator to register a fetcher class.</p> <pre><code>def register_fetcher(name: str) -&gt; Callable[[Type[BaseFetcher]], Type[BaseFetcher]]\n</code></pre> <p>Args:</p> <ul> <li><code>name</code> (str): The unique identifier for this fetcher</li> </ul> <p>Example:</p> <pre><code>@register_fetcher(\"my_source\")\nclass MySourceFetcher(BaseFetcher):\n    ...\n</code></pre>"},{"location":"api-reference/#get_available_sources","title":"get_available_sources()","text":"<p>Get list of all registered source names.</p> <pre><code>def get_available_sources() -&gt; List[str]\n</code></pre> <p>Returns: List of registered fetcher names.</p>"},{"location":"api-reference/#get_fetcher","title":"get_fetcher()","text":"<p>Get a fetcher instance by name.</p> <pre><code>def get_fetcher(name: str) -&gt; Optional[BaseFetcher]\n</code></pre> <p>Args:</p> <ul> <li><code>name</code> (str): The fetcher name to retrieve</li> </ul> <p>Returns: Fetcher instance or <code>None</code> if not found.</p>"},{"location":"api-reference/#fetch_all_articles","title":"fetch_all_articles()","text":"<p>Fetch articles from specified sources for the given topics.</p> <pre><code>def fetch_all_articles(\n    topics: Optional[List[str]] = None,\n    sources: Optional[List[str]] = None,\n    max_results: Optional[Dict[str, int]] = None,\n) -&gt; List[Article]\n</code></pre> <p>Args:</p> <ul> <li><code>topics</code> (Optional[List[str]]): List of topics to search for. Defaults to config topics.</li> <li><code>sources</code> (Optional[List[str]]): List of source names. Defaults to all sources.</li> <li><code>max_results</code> (Optional[Dict[str, int]]): Dict mapping source names to max results.</li> </ul> <p>Returns: Combined list of <code>Article</code> objects from all sources.</p>"},{"location":"api-reference/#ai_bloggerchains","title":"ai_blogger.chains","text":"<p>LangChain chains for content generation, scoring, and refinement.</p>"},{"location":"api-reference/#get_llm","title":"get_llm()","text":"<p>Get a configured LLM instance.</p> <pre><code>def get_llm(temperature: float = 0.7) -&gt; ChatOpenAI\n</code></pre> <p>Args:</p> <ul> <li><code>temperature</code> (float): The temperature setting for the LLM</li> </ul> <p>Returns: Configured <code>ChatOpenAI</code> instance.</p>"},{"location":"api-reference/#generate_candidates","title":"generate_candidates()","text":"<p>Generate candidate blog posts from articles.</p> <pre><code>def generate_candidates(\n    articles: List[Article],\n    num_candidates: int = DEFAULT_NUM_CANDIDATES\n) -&gt; List[CandidatePost]\n</code></pre> <p>Args:</p> <ul> <li><code>articles</code> (List[Article]): List of Article objects to use as sources</li> <li><code>num_candidates</code> (int): Number of candidate posts to generate</li> </ul> <p>Returns: List of <code>CandidatePost</code> objects.</p> <p>Raises: <code>ValueError</code> if parsing fails.</p>"},{"location":"api-reference/#score_candidate","title":"score_candidate()","text":"<p>Score a candidate blog post.</p> <pre><code>def score_candidate(candidate: CandidatePost) -&gt; ScoredPost\n</code></pre> <p>Args:</p> <ul> <li><code>candidate</code> (CandidatePost): The CandidatePost to score</li> </ul> <p>Returns: <code>ScoredPost</code> with scoring breakdown.</p>"},{"location":"api-reference/#score_candidates","title":"score_candidates()","text":"<p>Score all candidate posts.</p> <pre><code>def score_candidates(candidates: List[CandidatePost]) -&gt; List[ScoredPost]\n</code></pre> <p>Args:</p> <ul> <li><code>candidates</code> (List[CandidatePost]): List of CandidatePost objects to score</li> </ul> <p>Returns: List of <code>ScoredPost</code> objects, sorted by total score (descending).</p>"},{"location":"api-reference/#refine_winner","title":"refine_winner()","text":"<p>Refine and polish the winning blog post.</p> <pre><code>def refine_winner(winner: ScoredPost) -&gt; str\n</code></pre> <p>Args:</p> <ul> <li><code>winner</code> (ScoredPost): The winning ScoredPost to refine</li> </ul> <p>Returns: The refined blog post content as Markdown.</p>"},{"location":"api-reference/#ai_bloggerconfig","title":"ai_blogger.config","text":"<p>Configuration settings for the application.</p>"},{"location":"api-reference/#constants","title":"Constants","text":"Constant Type Default Description <code>TOPICS</code> List[str] See below Default search topics <code>SCORING_WEIGHTS</code> Dict[str, float] See below Scoring criteria weights <code>WEIGHTS_TOLERANCE</code> float 0.001 Floating-point tolerance <code>YOUTUBE_MAX_AGE_DAYS</code> int 7 Max age for YouTube videos <code>DEFAULT_MAX_RESULTS</code> int 5 Default results per source <code>SOURCE_DEFAULTS</code> Dict[str, int] See below Per-source result counts <code>DEFAULT_NUM_CANDIDATES</code> int 3 Number of candidates <code>DEFAULT_OUTPUT_DIR</code> str \"./posts\" Output directory <code>LLM_MODEL_NAME</code> str \"gpt-4\" OpenAI model name"},{"location":"api-reference/#default-topics","title":"Default Topics","text":"<pre><code>TOPICS = [\n    \"AI software engineering\",\n    \"agentic AI development\",\n    \"Copilot coding assistants\",\n    \"developer productivity\",\n    \"software engineering leadership\",\n    \"cybersecurity\",\n    \"AI security\",\n    \"dev tools\",\n    \"cloud infrastructure\",\n]\n</code></pre>"},{"location":"api-reference/#scoring-weights","title":"Scoring Weights","text":"<pre><code>SCORING_WEIGHTS = {\n    \"relevance\": 0.3,\n    \"originality\": 0.25,\n    \"depth\": 0.2,\n    \"clarity\": 0.15,\n    \"engagement\": 0.1,\n}\n</code></pre>"},{"location":"api-reference/#source-defaults","title":"Source Defaults","text":"<pre><code>SOURCE_DEFAULTS = {\n    \"hacker_news\": 10,\n    \"web\": 5,\n    \"youtube\": 5,\n}\n</code></pre>"},{"location":"api-reference/#ai_bloggerutils","title":"ai_blogger.utils","text":"<p>Utility functions.</p>"},{"location":"api-reference/#slugify","title":"slugify()","text":"<p>Convert text to a URL-friendly slug.</p> <pre><code>def slugify(text: str, max_length: int = 100) -&gt; str\n</code></pre> <p>Args:</p> <ul> <li><code>text</code> (str): The text to convert</li> <li><code>max_length</code> (int): Maximum length of the slug</li> </ul> <p>Returns: A URL-friendly slug version of the text.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; slugify(\"Hello World! 123\")\n'hello-world-123'\n</code></pre>"},{"location":"api-reference/#get_timestamp","title":"get_timestamp()","text":"<p>Get the current timestamp in ISO format.</p> <pre><code>def get_timestamp() -&gt; str\n</code></pre> <p>Returns: Current timestamp as a string.</p>"},{"location":"api-reference/#get_date_string","title":"get_date_string()","text":"<p>Get the current date as a string for filenames.</p> <pre><code>def get_date_string() -&gt; str\n</code></pre> <p>Returns: Current date in <code>YYYY-MM-DD</code> format.</p>"},{"location":"api-reference/#generate_filename","title":"generate_filename()","text":"<p>Generate a filename for a blog post.</p> <pre><code>def generate_filename(title: str) -&gt; str\n</code></pre> <p>Args:</p> <ul> <li><code>title</code> (str): The title of the blog post</li> </ul> <p>Returns: A filename in the format <code>YYYY-MM-DD-slug.md</code>.</p> <p>Example:</p> <pre><code>&gt;&gt;&gt; generate_filename(\"My Blog Post Title\")\n'2024-01-15-my-blog-post-title.md'\n</code></pre>"},{"location":"api-reference/#package-exports","title":"Package Exports","text":"<p>The main <code>ai_blogger</code> package exports the following:</p> <pre><code>from ai_blogger import (\n    # Configuration\n    TOPICS,\n\n    # Models\n    Article,\n    CandidatePost,\n    PostScore,\n    ScoredPost,\n\n    # Fetchers\n    BaseFetcher,\n    register_fetcher,\n    get_available_sources,\n    get_fetcher,\n    fetch_all_articles,\n\n    # Feedback API\n    FeedbackService,\n    ApprovalRequest,\n    RejectionRequest,\n    RevisionRequest,\n    FeedbackCategory,\n    FeedbackRating,\n    FeedbackEntry,\n    FeedbackStats,\n    FeedbackResponse,\n\n    # Utilities\n    slugify,\n    get_timestamp,\n    get_date_string,\n    generate_filename,\n)\n</code></pre>"},{"location":"api-reference/#ai_bloggerfeedback_api","title":"ai_blogger.feedback_api","text":"<p>The Feedback API provides structured endpoints for blog post approval, rejection, and editorial feedback. It is designed to support learning from editorial outcomes.</p>"},{"location":"api-reference/#feedbackservice","title":"FeedbackService","text":"<p>Service for managing blog post feedback and approvals.</p> <pre><code>class FeedbackService:\n    def __init__(self, storage: StorageBackend):\n        \"\"\"Initialize with a storage backend.\"\"\"\n\n    def approve_post(self, request: ApprovalRequest) -&gt; FeedbackResponse: ...\n    def reject_post(self, request: RejectionRequest) -&gt; FeedbackResponse: ...\n    def request_revision(self, request: RevisionRequest) -&gt; FeedbackResponse: ...\n    def get_post_feedback(self, post_id: str) -&gt; List[FeedbackEntry]: ...\n    def get_feedback_stats(self) -&gt; FeedbackStats: ...\n    def get_learning_data(self, limit: int = 100) -&gt; List[dict]: ...\n</code></pre> <p>Example:</p> <pre><code>from ai_blogger import FeedbackService, ApprovalRequest, create_storage\n\nstorage = create_storage()\nfeedback_service = FeedbackService(storage)\n\n# Approve a post\nresponse = feedback_service.approve_post(ApprovalRequest(\n    post_id=\"post-123\",\n    feedback=\"Excellent content!\",\n    actor=\"reviewer-1\",\n))\nprint(f\"Post approved: {response.success}\")\n</code></pre>"},{"location":"api-reference/#approvalrequest","title":"ApprovalRequest","text":"<p>Request to approve a blog post.</p> <pre><code>class ApprovalRequest(BaseModel):\n    post_id: str\n    feedback: Optional[str] = None\n    ratings: List[FeedbackRating] = []\n    actor: Optional[str] = None\n</code></pre>"},{"location":"api-reference/#rejectionrequest","title":"RejectionRequest","text":"<p>Request to reject a blog post. Feedback is required.</p> <pre><code>class RejectionRequest(BaseModel):\n    post_id: str\n    feedback: str  # Required\n    categories: List[FeedbackCategory] = []\n    ratings: List[FeedbackRating] = []\n    actor: Optional[str] = None\n</code></pre>"},{"location":"api-reference/#revisionrequest","title":"RevisionRequest","text":"<p>Request revision for a blog post. Feedback is required.</p> <pre><code>class RevisionRequest(BaseModel):\n    post_id: str\n    feedback: str  # Required\n    categories: List[FeedbackCategory] = []\n    ratings: List[FeedbackRating] = []\n    actor: Optional[str] = None\n</code></pre>"},{"location":"api-reference/#feedbackcategory","title":"FeedbackCategory","text":"<p>Categories for classifying editorial feedback.</p> Category Value Description QUALITY \"quality\" Overall quality issues RELEVANCE \"relevance\" Topic/content relevance ACCURACY \"accuracy\" Factual accuracy concerns CLARITY \"clarity\" Writing clarity issues ENGAGEMENT \"engagement\" Reader engagement concerns LENGTH \"length\" Content length issues STYLE \"style\" Writing style feedback SOURCES \"sources\" Source quality/citation issues OTHER \"other\" Miscellaneous feedback"},{"location":"api-reference/#feedbackrating","title":"FeedbackRating","text":"<p>Structured rating for a specific aspect of a blog post.</p> <pre><code>class FeedbackRating(BaseModel):\n    category: FeedbackCategory\n    score: int  # 1-5 scale (1=poor, 5=excellent)\n    comment: Optional[str] = None\n</code></pre> <p>Example:</p> <pre><code>from ai_blogger import FeedbackRating, FeedbackCategory\n\nrating = FeedbackRating(\n    category=FeedbackCategory.QUALITY,\n    score=4,\n    comment=\"Good overall quality, minor improvements needed\",\n)\n</code></pre>"},{"location":"api-reference/#feedbackentry","title":"FeedbackEntry","text":"<p>A feedback entry capturing editorial input for learning.</p> <pre><code>class FeedbackEntry(BaseModel):\n    id: str\n    post_id: str\n    job_id: Optional[str] = None\n    action: str  # \"approved\", \"rejected\", \"revision_requested\"\n    feedback: Optional[str] = None\n    categories: List[FeedbackCategory] = []\n    ratings: List[FeedbackRating] = []\n    actor: Optional[str] = None\n    post_scoring: Optional[Dict[str, Any]] = None\n    post_topic: Optional[str] = None\n    post_word_count: Optional[int] = None\n    created_at: datetime\n</code></pre>"},{"location":"api-reference/#feedbackstats","title":"FeedbackStats","text":"<p>Aggregated feedback statistics for learning.</p> <pre><code>class FeedbackStats(BaseModel):\n    total_feedback: int = 0\n    approvals: int = 0\n    rejections: int = 0\n    revisions: int = 0\n    approval_rate: Optional[float] = None\n    avg_quality_score: Optional[float] = None\n    avg_relevance_score: Optional[float] = None\n    avg_clarity_score: Optional[float] = None\n    avg_engagement_score: Optional[float] = None\n    common_rejection_categories: List[str] = []\n    avg_time_to_decision_hours: Optional[float] = None\n    feedback_by_topic: Dict[str, Dict[str, Any]] = {}\n</code></pre>"},{"location":"api-reference/#feedbackresponse","title":"FeedbackResponse","text":"<p>Response after providing feedback on a blog post.</p> <pre><code>class FeedbackResponse(BaseModel):\n    success: bool\n    post_id: str\n    new_status: str\n    feedback_id: str\n    message: str\n</code></pre>"},{"location":"api-reference/#feedback-learning-system","title":"Feedback Learning System","text":"<p>The Feedback API is designed to support learning from editorial outcomes. The <code>get_learning_data()</code> method returns structured data suitable for training or refining content generation algorithms.</p> <pre><code>from ai_blogger import FeedbackService, create_storage\n\nstorage = create_storage()\nfeedback_service = FeedbackService(storage)\n\n# Get learning data from past decisions\nlearning_data = feedback_service.get_learning_data(limit=100)\n\nfor entry in learning_data:\n    print(f\"Post: {entry['title']}\")\n    print(f\"Topic: {entry['topic']}\")\n    print(f\"Outcome: {entry['outcome']}\")  # 'approved' or 'rejected'\n    print(f\"Feedback: {entry['feedback']}\")\n    print(f\"Scoring: {entry['scoring']}\")\n    print(\"---\")\n</code></pre>"},{"location":"api-reference/#future-feedback-based-ranking","title":"Future Feedback-Based Ranking","text":"<p>The feedback data can be used to:</p> <ol> <li>Train ranking models: Use approval/rejection patterns to improve candidate scoring</li> <li>Topic preference learning: Identify which topics have higher approval rates</li> <li>Content style optimization: Learn from feedback categories to improve content generation</li> <li>Reviewer calibration: Track reviewer patterns for consistency</li> </ol>"},{"location":"api-reference/#ai_bloggerfrontend_api","title":"ai_blogger.frontend_api","text":"<p>The Frontend API provides RESTful HTTP endpoints for frontend clients to interact with the AI Blogger system. Built on FastAPI, it offers a complete API for job management, content preview, and approval workflows.</p>"},{"location":"api-reference/#installation","title":"Installation","text":"<p>The Frontend API requires additional dependencies:</p> <pre><code>pip install ai-blogger[api]\n</code></pre> <p>This installs FastAPI and Uvicorn for running the API server.</p>"},{"location":"api-reference/#quick-start","title":"Quick Start","text":"<pre><code>from ai_blogger import create_app\nimport uvicorn\n\n# Create and run the API\napp = create_app()\nuvicorn.run(app, host=\"0.0.0.0\", port=8000)\n</code></pre> <p>Or use the router in an existing FastAPI app:</p> <pre><code>from fastapi import FastAPI\nfrom ai_blogger import router\n\napp = FastAPI()\napp.include_router(router, prefix=\"/api\")\n</code></pre>"},{"location":"api-reference/#create_app","title":"create_app()","text":"<p>Factory function to create a configured FastAPI application.</p> <pre><code>def create_app(\n    title: str = \"AI Blogger Frontend API\",\n    description: str = \"RESTful API for AI Blogger job management and content workflow\",\n    version: str = \"1.0.0\",\n    cors_origins: Optional[List[str]] = None,\n) -&gt; FastAPI\n</code></pre> <p>Args:</p> <ul> <li><code>title</code> (str): API title for documentation.</li> <li><code>description</code> (str): API description.</li> <li><code>version</code> (str): API version.</li> <li><code>cors_origins</code> (Optional[List[str]]): CORS allowed origins. Defaults to <code>[\"*\"]</code>.</li> </ul> <p>Returns: Configured FastAPI application.</p>"},{"location":"api-reference/#router","title":"router","text":"<p>Pre-configured FastAPI APIRouter with all endpoints.</p> <pre><code>from ai_blogger import router\n</code></pre>"},{"location":"api-reference/#configure_services","title":"configure_services()","text":"<p>Configure custom service instances for dependency injection.</p> <pre><code>def configure_services(\n    job_service: Optional[JobService] = None,\n    feedback_service: Optional[FeedbackService] = None,\n    storage: Optional[StorageBackend] = None,\n) -&gt; None\n</code></pre> <p>Example:</p> <pre><code>from ai_blogger import configure_services, JobService, FeedbackService, create_storage\n\n# Custom configuration\nstorage = create_storage(\"postgres\", connection_string=\"postgresql://...\")\njob_service = JobService(\"/custom/jobs/dir\")\nfeedback_service = FeedbackService(storage)\n\nconfigure_services(\n    job_service=job_service,\n    feedback_service=feedback_service,\n    storage=storage,\n)\n</code></pre>"},{"location":"api-reference/#api-endpoints","title":"API Endpoints","text":""},{"location":"api-reference/#health-check","title":"Health Check","text":"Method Endpoint Description GET <code>/api/health</code> Check API and service health <p>Response:</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"job_service\": true,\n  \"feedback_service\": true,\n  \"storage\": true\n}\n</code></pre>"},{"location":"api-reference/#job-management","title":"Job Management","text":"Method Endpoint Description POST <code>/api/jobs</code> Submit a new job GET <code>/api/jobs</code> List all jobs GET <code>/api/jobs/{job_id}</code> Get job status GET <code>/api/jobs/correlation/{correlation_id}</code> Get job by correlation ID DELETE <code>/api/jobs/{job_id}</code> Delete a job POST <code>/api/jobs/{job_id}/execute</code> Execute a pending job <p>Submit Job Request:</p> <pre><code>{\n  \"topics\": [\"AI\", \"machine learning\"],\n  \"sources\": [\"hacker_news\", \"youtube\"],\n  \"num_candidates\": 3,\n  \"max_results\": {\"hacker_news\": 10, \"youtube\": 5},\n  \"correlation_id\": \"unique-request-id\"\n}\n</code></pre> <p>Submit Job Response:</p> <pre><code>{\n  \"job_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"correlation_id\": \"unique-request-id\",\n  \"status\": \"pending\",\n  \"message\": \"Job submitted successfully\",\n  \"is_duplicate\": false\n}\n</code></pre> <p>Job Status Response:</p> <pre><code>{\n  \"job_id\": \"550e8400-e29b-41d4-a716-446655440000\",\n  \"correlation_id\": \"unique-request-id\",\n  \"status\": \"completed\",\n  \"created_at\": \"2024-01-15T10:30:00Z\",\n  \"updated_at\": \"2024-01-15T10:35:00Z\",\n  \"started_at\": \"2024-01-15T10:30:05Z\",\n  \"completed_at\": \"2024-01-15T10:35:00Z\",\n  \"result\": {\n    \"markdown_preview\": {...},\n    \"scoring\": {...},\n    \"articles_fetched\": 15,\n    \"candidates_generated\": 3\n  },\n  \"error\": null\n}\n</code></pre>"},{"location":"api-reference/#markdown-preview","title":"Markdown Preview","text":"Method Endpoint Description GET <code>/api/jobs/{job_id}/preview</code> Get markdown preview for completed job <p>Response:</p> <pre><code>{\n  \"success\": true,\n  \"preview\": {\n    \"title\": \"AI Trends in 2024\",\n    \"content\": \"# AI Trends in 2024\\n\\n...\",\n    \"word_count\": 1500,\n    \"topic\": \"AI software engineering\",\n    \"sources\": [\"https://example.com/article1\"]\n  },\n  \"message\": \"Preview available\"\n}\n</code></pre>"},{"location":"api-reference/#approval-workflow","title":"Approval Workflow","text":"Method Endpoint Description POST <code>/api/posts/{post_id}/approve</code> Approve a blog post POST <code>/api/posts/{post_id}/reject</code> Reject a blog post POST <code>/api/posts/{post_id}/revision</code> Request revision GET <code>/api/posts/{post_id}/feedback</code> Get post feedback history <p>Approve Request:</p> <pre><code>{\n  \"feedback\": \"Excellent content!\",\n  \"ratings\": [\n    {\"category\": \"quality\", \"score\": 5, \"comment\": \"Great writing\"}\n  ],\n  \"actor\": \"reviewer-1\"\n}\n</code></pre> <p>Reject Request:</p> <pre><code>{\n  \"feedback\": \"Needs more research\",\n  \"categories\": [\"accuracy\", \"sources\"],\n  \"ratings\": [\n    {\"category\": \"accuracy\", \"score\": 2}\n  ],\n  \"actor\": \"reviewer-1\"\n}\n</code></pre> <p>Feedback Response:</p> <pre><code>{\n  \"success\": true,\n  \"post_id\": \"post-123\",\n  \"new_status\": \"approved\",\n  \"feedback_id\": \"feedback-456\",\n  \"message\": \"Post approved successfully\"\n}\n</code></pre>"},{"location":"api-reference/#feedback-statistics","title":"Feedback Statistics","text":"Method Endpoint Description GET <code>/api/feedback/stats</code> Get aggregated feedback statistics GET <code>/api/feedback/learning</code> Get learning data for ML training <p>Stats Response:</p> <pre><code>{\n  \"total_feedback\": 100,\n  \"approvals\": 70,\n  \"rejections\": 20,\n  \"revisions\": 10,\n  \"approval_rate\": 70.0,\n  \"feedback_by_topic\": {\n    \"AI software engineering\": {\n      \"total\": 30,\n      \"approved\": 25,\n      \"approval_rate\": 83.33\n    }\n  }\n}\n</code></pre>"},{"location":"api-reference/#error-handling","title":"Error Handling","text":"<p>All endpoints return appropriate HTTP status codes:</p> Code Description 200 Success 201 Created (for POST /api/jobs) 204 No Content (for DELETE) 400 Bad Request (validation errors) 404 Not Found (resource doesn't exist) 500 Internal Server Error <p>Error responses include a <code>detail</code> field:</p> <pre><code>{\n  \"detail\": \"Job abc123 not found\"\n}\n</code></pre>"},{"location":"api-reference/#cors-configuration","title":"CORS Configuration","text":"<p>By default, CORS is enabled for all origins. Customize in production:</p> <pre><code>app = create_app(cors_origins=[\"https://myapp.example.com\"])\n</code></pre>"},{"location":"api-reference/#running-the-server","title":"Running the Server","text":"<pre><code># Development\nuvicorn ai_blogger.frontend_api:create_app --factory --reload\n\n# Production\nuvicorn ai_blogger.frontend_api:create_app --factory --host 0.0.0.0 --port 8000\n</code></pre> <p>Or with the module directly:</p> <pre><code>python -m ai_blogger.frontend_api\n</code></pre>"},{"location":"api-reference/#interactive-documentation","title":"Interactive Documentation","text":"<p>When running, access:</p> <ul> <li>Swagger UI: <code>http://localhost:8000/docs</code></li> <li>ReDoc: <code>http://localhost:8000/redoc</code></li> </ul>"},{"location":"api-reference/#frontend-ui","title":"Frontend UI","text":"<p>The AI Blogger includes a React-based frontend UI for job management and approval workflows.</p>"},{"location":"api-reference/#building-the-frontend","title":"Building the Frontend","text":"<pre><code>cd frontend\nnpm install\nnpm run build\n</code></pre>"},{"location":"api-reference/#running-with-frontend","title":"Running with Frontend","text":"<p>After building, the frontend is automatically served by the Python backend:</p> <pre><code># The create_app function will detect and serve frontend/dist\nuvicorn ai_blogger.frontend_api:create_app --factory --host 0.0.0.0 --port 8000\n</code></pre> <p>Access the UI at <code>http://localhost:8000/</code>.</p>"},{"location":"api-reference/#frontend-features","title":"Frontend Features","text":"<p>The frontend provides:</p> <ol> <li>Job Submission Form: Create new blog post generation jobs with:</li> <li>Topic selection (default topics + custom topics)</li> <li>Source selection (Hacker News, Web Search, YouTube)</li> <li>Number of candidates slider (1-10)</li> <li> <p>Correlation ID for idempotency</p> </li> <li> <p>Job List View: Monitor all jobs with:</p> </li> <li>Real-time status updates (polling every 5 seconds)</li> <li>Color-coded status badges</li> <li>Progress bars for in-progress jobs</li> <li> <p>Quick job selection</p> </li> <li> <p>Post Review Panel: Review and approve completed jobs with:</p> </li> <li>Full markdown preview</li> <li>Scoring breakdown visualization</li> <li>Approve/Reject/Request Revision buttons</li> <li>Feedback categories and comments</li> <li>Job execution controls</li> </ol>"},{"location":"api-reference/#development-mode","title":"Development Mode","text":"<p>For frontend development with hot reload:</p> <pre><code># Terminal 1: Run the Python backend\nuvicorn ai_blogger.frontend_api:create_app --factory --reload --port 8000\n\n# Terminal 2: Run Vite dev server\ncd frontend\nnpm run dev\n</code></pre> <p>The Vite dev server proxies API requests to the backend.</p>"},{"location":"api-reference/#see-also","title":"See Also","text":"<ul> <li>Architecture - System design overview</li> <li>Developer Guide - Extension guide</li> <li>Operations - Deployment guide</li> <li>Persistence - Storage layer documentation</li> </ul>"},{"location":"architecture/","title":"Architecture","text":"<p>This document provides an overview of the AI Blogger (Inker) system architecture, including component design, data flow, and integration patterns.</p>"},{"location":"architecture/#system-overview","title":"System Overview","text":"<p>AI Blogger follows a modular pipeline architecture that separates concerns into distinct phases:</p> <pre><code>flowchart TB\n    subgraph Input[\"Input Layer\"]\n        CLI[CLI Interface]\n        CONFIG[Configuration]\n    end\n\n    subgraph Fetching[\"Fetching Layer\"]\n        FR[Fetcher Registry]\n        HN[HackerNews Fetcher]\n        WS[Web Search Fetcher]\n        YT[YouTube Fetcher]\n    end\n\n    subgraph Processing[\"Processing Layer\"]\n        GEN[Candidate Generator]\n        SCORE[Scoring Engine]\n        REFINE[Refinement Chain]\n    end\n\n    subgraph LLM[\"LLM Integration\"]\n        LC[LangChain]\n        OAI[OpenAI GPT-4]\n    end\n\n    subgraph Output[\"Output Layer\"]\n        MD[Markdown Writer]\n        FS[File System]\n    end\n\n    CLI --&gt; FR\n    CONFIG --&gt; CLI\n    FR --&gt; HN &amp; WS &amp; YT\n    HN &amp; WS &amp; YT --&gt; GEN\n    GEN --&gt; SCORE\n    SCORE --&gt; REFINE\n    GEN &amp; SCORE &amp; REFINE --&gt; LC\n    LC --&gt; OAI\n    REFINE --&gt; MD\n    MD --&gt; FS</code></pre>"},{"location":"architecture/#component-architecture","title":"Component Architecture","text":""},{"location":"architecture/#core-components","title":"Core Components","text":"<pre><code>classDiagram\n    class BaseFetcher {\n        &lt;&lt;abstract&gt;&gt;\n        +name: str\n        +env_key: str\n        +description: str\n        +is_available() bool\n        +fetch(topic, max_results) List~Article~\n    }\n\n    class HackerNewsFetcher {\n        +name = \"hacker_news\"\n        +fetch(topic, max_results) List~Article~\n    }\n\n    class WebSearchFetcher {\n        +name = \"web\"\n        +env_key = \"TAVILY_API_KEY\"\n        +fetch(topic, max_results) List~Article~\n    }\n\n    class YouTubeFetcher {\n        +name = \"youtube\"\n        +env_key = \"YOUTUBE_API_KEY\"\n        +fetch(topic, max_results) List~Article~\n    }\n\n    BaseFetcher &lt;|-- HackerNewsFetcher\n    BaseFetcher &lt;|-- WebSearchFetcher\n    BaseFetcher &lt;|-- YouTubeFetcher</code></pre>"},{"location":"architecture/#data-models","title":"Data Models","text":"<pre><code>classDiagram\n    class Article {\n        +title: str\n        +url: HttpUrl\n        +source: str\n        +summary: str\n        +topic: str\n        +thumbnail: Optional~str~\n    }\n\n    class CandidatePost {\n        +title: str\n        +content: str\n        +sources: List~str~\n        +topic: str\n    }\n\n    class PostScore {\n        +relevance: float\n        +originality: float\n        +depth: float\n        +clarity: float\n        +engagement: float\n        +total: float\n        +reasoning: str\n    }\n\n    class ScoredPost {\n        +candidate: CandidatePost\n        +score: PostScore\n    }\n\n    ScoredPost --&gt; CandidatePost\n    ScoredPost --&gt; PostScore</code></pre>"},{"location":"architecture/#pipeline-flow","title":"Pipeline Flow","text":"<p>The content generation pipeline follows these sequential phases:</p> <pre><code>sequenceDiagram\n    participant CLI as CLI\n    participant Fetchers as Fetcher Layer\n    participant Generator as Generator Chain\n    participant Scorer as Scoring Chain\n    participant Refiner as Refiner Chain\n    participant FS as File System\n\n    CLI-&gt;&gt;Fetchers: fetch_all_articles(topics, sources)\n    Fetchers--&gt;&gt;CLI: List[Article]\n\n    CLI-&gt;&gt;Generator: generate_candidates(articles, num)\n    Generator--&gt;&gt;CLI: List[CandidatePost]\n\n    loop For each candidate\n        CLI-&gt;&gt;Scorer: score_candidate(candidate)\n        Scorer--&gt;&gt;CLI: ScoredPost\n    end\n\n    CLI-&gt;&gt;CLI: Sort by score, select winner\n\n    CLI-&gt;&gt;Refiner: refine_winner(winner)\n    Refiner--&gt;&gt;CLI: Refined Markdown\n\n    CLI-&gt;&gt;FS: Write to file\n    FS--&gt;&gt;CLI: Success</code></pre>"},{"location":"architecture/#fetcher-architecture","title":"Fetcher Architecture","text":"<p>The fetcher subsystem uses a registry pattern for extensibility:</p> <pre><code>flowchart LR\n    subgraph Registry[\"Fetcher Registry\"]\n        R[(Registry Dict)]\n    end\n\n    subgraph Decorator[\"Registration\"]\n        D[\"@register_fetcher()\"]\n    end\n\n    subgraph Fetchers[\"Fetcher Classes\"]\n        HN[HackerNewsFetcher]\n        WS[WebSearchFetcher]\n        YT[YouTubeFetcher]\n        CUSTOM[CustomFetcher...]\n    end\n\n    D --&gt; R\n    HN &amp; WS &amp; YT &amp; CUSTOM --&gt; D\n\n    subgraph Functions[\"Access Functions\"]\n        GA[get_available_sources]\n        GF[get_fetcher]\n    end\n\n    R --&gt; GA &amp; GF</code></pre>"},{"location":"architecture/#adding-a-new-fetcher","title":"Adding a New Fetcher","text":"<pre><code>from ai_blogger.fetchers import BaseFetcher, register_fetcher\n\n@register_fetcher(\"my_source\")\nclass MySourceFetcher(BaseFetcher):\n    name = \"my_source\"\n    env_key = \"MY_SOURCE_API_KEY\"  # Optional\n    description = \"Fetch from My Source\"\n\n    def fetch(self, topic: str, max_results: int) -&gt; List[Article]:\n        self._validate_inputs(topic, max_results)\n        # Implementation here\n        return articles\n</code></pre>"},{"location":"architecture/#langchain-integration","title":"LangChain Integration","text":"<p>AI Blogger uses LangChain for all LLM interactions:</p> <pre><code>flowchart TB\n    subgraph Chains[\"LangChain Chains\"]\n        GC[\"generate_candidates()\"]\n        SC[\"score_candidate()\"]\n        RC[\"refine_winner()\"]\n    end\n\n    subgraph Templates[\"Prompt Templates\"]\n        GT[Generator Template]\n        ST[Scorer Template]\n        RT[Refiner Template]\n    end\n\n    subgraph LLM[\"LLM\"]\n        GPT[ChatOpenAI]\n    end\n\n    GT --&gt; GC\n    ST --&gt; SC\n    RT --&gt; RC\n\n    GC &amp; SC &amp; RC --&gt; GPT</code></pre>"},{"location":"architecture/#chain-configuration","title":"Chain Configuration","text":"Chain Temperature Purpose Generator 0.8 Creative content generation Scorer 0.3 Consistent, objective scoring Refiner 0.6 Balanced refinement"},{"location":"architecture/#scoring-system","title":"Scoring System","text":"<p>The scoring system uses weighted criteria:</p> <pre><code>pie title Scoring Weights\n    \"Relevance (30%)\" : 30\n    \"Originality (25%)\" : 25\n    \"Depth (20%)\" : 20\n    \"Clarity (15%)\" : 15\n    \"Engagement (10%)\" : 10</code></pre>"},{"location":"architecture/#scoring-criteria","title":"Scoring Criteria","text":"Criterion Weight Description Relevance 0.30 Topic relevance to software engineering Originality 0.25 Unique perspective and insights Depth 0.20 Thoroughness of exploration Clarity 0.15 Writing quality and structure Engagement 0.10 Reader attention capture"},{"location":"architecture/#directory-structure","title":"Directory Structure","text":"<pre><code>ai_blogger/\n\u251c\u2500\u2500 __init__.py       # Package exports\n\u251c\u2500\u2500 __main__.py       # CLI entrypoint\n\u251c\u2500\u2500 config.py         # Configuration settings\n\u251c\u2500\u2500 fetchers.py       # Modular fetcher architecture\n\u251c\u2500\u2500 chains.py         # LangChain chains\n\u251c\u2500\u2500 models.py         # Pydantic data models\n\u251c\u2500\u2500 utils.py          # Utility functions\n\u251c\u2500\u2500 job_api.py        # Job API service\n\u251c\u2500\u2500 job_models.py     # Job data models\n\u251c\u2500\u2500 job_store.py      # File-based job storage\n\u2514\u2500\u2500 persistence/      # Modular persistence layer\n    \u251c\u2500\u2500 __init__.py   # Persistence exports\n    \u251c\u2500\u2500 base.py       # Abstract storage interface\n    \u251c\u2500\u2500 factory.py    # Storage factory\n    \u251c\u2500\u2500 models.py     # Persistence models\n    \u251c\u2500\u2500 sqlite_storage.py    # SQLite backend\n    \u2514\u2500\u2500 postgres_storage.py  # PostgreSQL backend\n</code></pre>"},{"location":"architecture/#persistence-architecture","title":"Persistence Architecture","text":"<p>The persistence layer provides modular storage with multiple backend options:</p> <pre><code>flowchart TB\n    subgraph API[\"API Layer\"]\n        JOB[JobService]\n        REST[REST Endpoints]\n    end\n\n    subgraph Persistence[\"Persistence Layer\"]\n        FACTORY[StorageFactory]\n        SQLITE[SQLiteStorage]\n        PG[PostgresStorage]\n    end\n\n    subgraph Data[\"Data Stores\"]\n        SQLITE_DB[(SQLite)]\n        PG_DB[(PostgreSQL)]\n    end\n\n    JOB &amp; REST --&gt; FACTORY\n    FACTORY --&gt; SQLITE &amp; PG\n    SQLITE --&gt; SQLITE_DB\n    PG --&gt; PG_DB</code></pre>"},{"location":"architecture/#supported-backends","title":"Supported Backends","text":"Backend Use Case Requirements SQLite Development, local storage None (built-in) PostgreSQL Production deployments psycopg2 <p>See Persistence Layer for detailed documentation.</p>"},{"location":"architecture/#external-dependencies","title":"External Dependencies","text":"<pre><code>flowchart TB\n    subgraph External[\"External Services\"]\n        OAI[OpenAI API]\n        TAV[Tavily API]\n        YT[YouTube Data API]\n        HN[HN Algolia API]\n    end\n\n    subgraph Internal[\"AI Blogger\"]\n        CHAINS[chains.py]\n        WEB[WebSearchFetcher]\n        YOUTUBE[YouTubeFetcher]\n        HACKER[HackerNewsFetcher]\n    end\n\n    CHAINS --&gt; OAI\n    WEB --&gt; TAV\n    YOUTUBE --&gt; YT\n    HACKER --&gt; HN</code></pre>"},{"location":"architecture/#api-usage-notes","title":"API Usage Notes","text":"API Authentication Rate Limits OpenAI API Key Per-minute/per-day based on tier Tavily API Key Plan-dependent YouTube Data API API Key 10,000 units/day default HN Algolia None Reasonable use"},{"location":"architecture/#error-handling","title":"Error Handling","text":"<p>The system implements graceful degradation:</p> <pre><code>flowchart TD\n    START[Fetch Request] --&gt; CHECK{API Available?}\n    CHECK --&gt;|Yes| FETCH[Execute Fetch]\n    CHECK --&gt;|No| SKIP[Skip Source]\n\n    FETCH --&gt; VALIDATE{Valid Response?}\n    VALIDATE --&gt;|Yes| PARSE[Parse Articles]\n    VALIDATE --&gt;|No| LOG[Log Error]\n\n    PARSE --&gt; RETURN[Return Articles]\n    LOG --&gt; EMPTY[Return Empty List]\n    SKIP --&gt; EMPTY\n\n    RETURN --&gt; CONTINUE[Continue Pipeline]\n    EMPTY --&gt; CONTINUE</code></pre>"},{"location":"architecture/#see-also","title":"See Also","text":"<ul> <li>Persistence Layer - Storage backend documentation</li> <li>Developer Guide - Extending the system</li> <li>API Reference - Detailed module documentation</li> <li>Operations - Deployment and monitoring</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to AI Blogger (Inker)! This guide will help you get started.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<ul> <li>\ud83d\udc1b Report bugs - Submit issues for bugs you find</li> <li>\ud83d\udca1 Suggest features - Propose new features or enhancements</li> <li>\ud83d\udcdd Improve documentation - Fix typos, clarify explanations</li> <li>\ud83d\udd27 Submit code - Fix bugs or implement features</li> <li>\ud83e\uddea Add tests - Improve test coverage</li> </ul>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<pre><code>flowchart LR\n    FORK[Fork Repo] --&gt; CLONE[Clone Fork]\n    CLONE --&gt; BRANCH[Create Branch]\n    BRANCH --&gt; CODE[Make Changes]\n    CODE --&gt; TEST[Run Tests]\n    TEST --&gt; COMMIT[Commit]\n    COMMIT --&gt; PUSH[Push to Fork]\n    PUSH --&gt; PR[Create PR]\n    PR --&gt; REVIEW[Code Review]\n    REVIEW --&gt; MERGE[Merge]</code></pre>"},{"location":"contributing/#getting-started","title":"Getting Started","text":""},{"location":"contributing/#1-fork-and-clone","title":"1. Fork and Clone","text":"<pre><code># Fork the repository on GitHub, then:\ngit clone https://github.com/YOUR-USERNAME/inker.git\ncd inker\n</code></pre>"},{"location":"contributing/#2-set-up-development-environment","title":"2. Set Up Development Environment","text":"<pre><code># Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode\npip install -e \".[dev]\"\n</code></pre>"},{"location":"contributing/#3-create-a-branch","title":"3. Create a Branch","text":"<pre><code># Create a branch for your changes\ngit checkout -b feature/my-feature\n# or\ngit checkout -b fix/bug-description\n</code></pre>"},{"location":"contributing/#code-standards","title":"Code Standards","text":""},{"location":"contributing/#style-guide","title":"Style Guide","text":"<ul> <li>Python: Follow PEP 8</li> <li>Line length: Maximum 120 characters</li> <li>Imports: Sorted with isort</li> <li>Formatting: Black</li> </ul>"},{"location":"contributing/#formatting-commands","title":"Formatting Commands","text":"<pre><code># Format code\nblack ai_blogger/\nisort ai_blogger/\n\n# Check formatting\nblack --check ai_blogger/\nisort --check-only ai_blogger/\n</code></pre>"},{"location":"contributing/#linting","title":"Linting","text":"<pre><code># Run flake8\nflake8 ai_blogger/ --max-line-length=120\n\n# Run mypy\nmypy ai_blogger/\n</code></pre>"},{"location":"contributing/#type-hints","title":"Type Hints","text":"<p>Use type hints for all function signatures:</p> <pre><code>def my_function(name: str, count: int = 10) -&gt; List[str]:\n    \"\"\"Description of function.\n\n    Args:\n        name: The name parameter.\n        count: Number of items.\n\n    Returns:\n        List of string results.\n    \"\"\"\n    return [name] * count\n</code></pre>"},{"location":"contributing/#testing","title":"Testing","text":""},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest tests/ -v\n\n# Run with coverage\npytest tests/ -v --cov=ai_blogger --cov-report=html\n\n# Run specific test file\npytest tests/test_ai_blogger.py -v\n\n# Run specific test\npytest tests/test_ai_blogger.py::test_slugify -v\n</code></pre>"},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom ai_blogger import Article\n\ndef test_article_creation():\n    \"\"\"Test Article model creation.\"\"\"\n    article = Article(\n        title=\"Test Article\",\n        url=\"https://example.com\",\n        source=\"test\",\n        summary=\"Summary\",\n        topic=\"testing\",\n    )\n    assert article.title == \"Test Article\"\n    assert article.source == \"test\"\n\ndef test_invalid_article():\n    \"\"\"Test that invalid Article raises error.\"\"\"\n    with pytest.raises(ValueError):\n        Article(\n            title=\"\",  # Empty title should be valid (Pydantic)\n            url=\"not-a-url\",  # Invalid URL\n            source=\"test\",\n            summary=\"\",\n            topic=\"\",\n        )\n</code></pre>"},{"location":"contributing/#bdd-tests","title":"BDD Tests","text":"<p>For complex features, consider adding BDD tests:</p> <pre><code># tests/features/my_feature.feature\nFeature: My Feature\n  As a user\n  I want to do something\n  So that I achieve a goal\n\n  Scenario: Basic usage\n    Given initial state\n    When I perform action\n    Then I should see result\n</code></pre>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"contributing/#before-submitting","title":"Before Submitting","text":"<ol> <li>Update documentation if needed</li> <li>Add tests for new functionality</li> <li>Run all checks:</li> </ol> <pre><code># Format\nblack ai_blogger/\nisort ai_blogger/\n\n# Lint\nflake8 ai_blogger/\n\n# Test\npytest tests/ -v\n</code></pre>"},{"location":"contributing/#pr-guidelines","title":"PR Guidelines","text":"<ul> <li>Use a clear, descriptive title</li> <li>Reference related issues (e.g., \"Fixes #123\")</li> <li>Describe what changes you made and why</li> <li>Include test results</li> <li>Add screenshots for UI changes</li> </ul>"},{"location":"contributing/#pr-template","title":"PR Template","text":"<pre><code>## Description\nBrief description of changes.\n\n## Related Issue\nFixes #123\n\n## Type of Change\n- [ ] Bug fix\n- [ ] New feature\n- [ ] Documentation update\n- [ ] Refactoring\n\n## Testing\n- [ ] Added new tests\n- [ ] All tests pass\n- [ ] Tested manually\n\n## Checklist\n- [ ] Code follows style guidelines\n- [ ] Self-reviewed code\n- [ ] Documentation updated\n- [ ] No new warnings\n</code></pre>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Follow conventional commit format:</p> <pre><code>type(scope): description\n\n[optional body]\n\n[optional footer]\n</code></pre>"},{"location":"contributing/#types","title":"Types","text":"<ul> <li><code>feat</code>: New feature</li> <li><code>fix</code>: Bug fix</li> <li><code>docs</code>: Documentation only</li> <li><code>style</code>: Formatting, no code change</li> <li><code>refactor</code>: Refactoring code</li> <li><code>test</code>: Adding tests</li> <li><code>chore</code>: Maintenance tasks</li> </ul>"},{"location":"contributing/#examples","title":"Examples","text":"<pre><code>feat(fetchers): add Reddit fetcher\n\nAdds a new fetcher for Reddit posts using the Reddit API.\n\nCloses #42\n</code></pre> <pre><code>fix(youtube): handle API rate limits\n\nAdds exponential backoff when YouTube API returns 429.\n\nFixes #56\n</code></pre> <pre><code>docs: update installation instructions\n\n- Add Windows-specific commands\n- Clarify Python version requirements\n</code></pre>"},{"location":"contributing/#adding-new-features","title":"Adding New Features","text":""},{"location":"contributing/#adding-a-new-fetcher","title":"Adding a New Fetcher","text":"<ol> <li>Create the fetcher class in <code>ai_blogger/fetchers.py</code>:</li> </ol> <pre><code>@register_fetcher(\"my_source\")\nclass MySourceFetcher(BaseFetcher):\n    name = \"my_source\"\n    env_key = \"MY_SOURCE_API_KEY\"\n    description = \"Fetch from My Source\"\n\n    def fetch(self, topic: str, max_results: int) -&gt; List[Article]:\n        self._validate_inputs(topic, max_results)\n        # Implementation\n        return articles\n</code></pre> <ol> <li>Add tests in <code>tests/test_ai_blogger.py</code>:</li> </ol> <pre><code>def test_my_source_fetcher():\n    from ai_blogger import get_fetcher\n    fetcher = get_fetcher(\"my_source\")\n    assert fetcher is not None\n    assert fetcher.name == \"my_source\"\n</code></pre> <ol> <li>Update documentation if needed</li> </ol>"},{"location":"contributing/#modifying-llm-chains","title":"Modifying LLM Chains","text":"<ol> <li>Make changes in <code>ai_blogger/chains.py</code></li> <li>Test with different inputs:</li> </ol> <pre><code>from ai_blogger.chains import generate_candidates\nfrom ai_blogger.models import Article\n\n# Test with sample data\narticles = [\n    Article(\n        title=\"Test\",\n        url=\"https://example.com\",\n        source=\"test\",\n        summary=\"Test summary\",\n        topic=\"AI\",\n    )\n]\n\ncandidates = generate_candidates(articles, num_candidates=1)\nprint(candidates)\n</code></pre>"},{"location":"contributing/#release-process","title":"Release Process","text":"<p>Releases are handled by maintainers:</p> <ol> <li>Update version in <code>pyproject.toml</code></li> <li>Update CHANGELOG</li> <li>Create release tag</li> <li>GitHub Actions builds and publishes</li> </ol>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Questions: Open a Discussion</li> <li>Bugs: Open an Issue</li> <li>Chat: Join our community (if available)</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers</li> <li>Focus on constructive feedback</li> <li>Assume good intentions</li> </ul>"},{"location":"contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p> <p>Thank you for contributing to AI Blogger! \ud83c\udf89</p>"},{"location":"developer-guide/","title":"Developer Guide","text":"<p>This guide covers extending and customizing AI Blogger (Inker) for developers.</p>"},{"location":"developer-guide/#development-setup","title":"Development Setup","text":""},{"location":"developer-guide/#prerequisites","title":"Prerequisites","text":"<ul> <li>Python 3.9+</li> <li>Git</li> <li>Virtual environment tool (venv, conda, etc.)</li> </ul>"},{"location":"developer-guide/#setting-up-the-development-environment","title":"Setting Up the Development Environment","text":"<pre><code># Clone the repository\ngit clone https://github.com/ianlintner/inker.git\ncd inker\n\n# Create and activate virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode with dev dependencies\npip install -e \".[dev]\"\n\n# Set up environment variables\nexport OPENAI_API_KEY=\"your-key\"\nexport TAVILY_API_KEY=\"your-key\"\nexport YOUTUBE_API_KEY=\"your-key\"\n</code></pre>"},{"location":"developer-guide/#project-structure","title":"Project Structure","text":"<pre><code>inker/\n\u251c\u2500\u2500 ai_blogger/           # Main package\n\u2502   \u251c\u2500\u2500 __init__.py       # Package exports\n\u2502   \u251c\u2500\u2500 __main__.py       # CLI entrypoint\n\u2502   \u251c\u2500\u2500 chains.py         # LangChain chains\n\u2502   \u251c\u2500\u2500 config.py         # Configuration\n\u2502   \u251c\u2500\u2500 fetchers.py       # Fetcher implementations\n\u2502   \u251c\u2500\u2500 models.py         # Pydantic models\n\u2502   \u2514\u2500\u2500 utils.py          # Utility functions\n\u251c\u2500\u2500 tests/                # Test suite\n\u2502   \u251c\u2500\u2500 features/         # BDD feature files\n\u2502   \u251c\u2500\u2500 step_defs/        # Step definitions\n\u2502   \u2514\u2500\u2500 test_ai_blogger.py\n\u251c\u2500\u2500 docs/                 # Documentation\n\u251c\u2500\u2500 pyproject.toml        # Project configuration\n\u251c\u2500\u2500 requirements.txt      # Dependencies\n\u251c\u2500\u2500 Dockerfile            # Container definition\n\u2514\u2500\u2500 mkdocs.yml            # Documentation config\n</code></pre>"},{"location":"developer-guide/#adding-a-new-fetcher","title":"Adding a New Fetcher","text":"<p>The fetcher architecture is designed for easy extension. Follow these steps to add a new news source:</p>"},{"location":"developer-guide/#step-1-create-the-fetcher-class","title":"Step 1: Create the Fetcher Class","text":"<pre><code># In ai_blogger/fetchers.py or a new module\n\nfrom typing import List\nfrom ai_blogger.fetchers import BaseFetcher, register_fetcher\nfrom ai_blogger.models import Article\n\n@register_fetcher(\"my_source\")\nclass MySourceFetcher(BaseFetcher):\n    \"\"\"Fetcher for My Source articles.\"\"\"\n\n    name = \"my_source\"\n    env_key = \"MY_SOURCE_API_KEY\"  # Set to None if no key needed\n    description = \"Fetch articles from My Source\"\n\n    def fetch(self, topic: str, max_results: int) -&gt; List[Article]:\n        \"\"\"Fetch articles from My Source.\n\n        Args:\n            topic: The topic to search for.\n            max_results: Maximum number of results.\n\n        Returns:\n            List of Article objects.\n        \"\"\"\n        # Validate inputs\n        self._validate_inputs(topic, max_results)\n\n        articles = []\n        api_key = os.environ.get(self.env_key)\n\n        if not api_key:\n            logger.warning(self.get_missing_key_message())\n            return articles\n\n        try:\n            # Your implementation here\n            # Make API calls, parse responses, etc.\n\n            for item in response_data:\n                article = Article(\n                    title=item[\"title\"],\n                    url=item[\"url\"],\n                    source=self.name,\n                    summary=item[\"description\"][:500],\n                    topic=topic,\n                )\n                articles.append(article)\n\n        except requests.RequestException as e:\n            logger.error(f\"Error fetching from {self.name}: {e}\")\n\n        return articles\n</code></pre>"},{"location":"developer-guide/#step-2-update-configuration-optional","title":"Step 2: Update Configuration (Optional)","text":"<p>Add default result count for your source:</p> <pre><code># In ai_blogger/config.py\n\nSOURCE_DEFAULTS: Dict[str, int] = {\n    \"hacker_news\": 10,\n    \"web\": 5,\n    \"youtube\": 5,\n    \"my_source\": 10,  # Add your source\n}\n</code></pre>"},{"location":"developer-guide/#step-3-add-tests","title":"Step 3: Add Tests","text":"<pre><code># In tests/test_ai_blogger.py\n\ndef test_my_source_fetcher():\n    \"\"\"Test that my_source fetcher is registered.\"\"\"\n    from ai_blogger import get_fetcher\n\n    fetcher = get_fetcher(\"my_source\")\n    assert fetcher is not None\n    assert fetcher.name == \"my_source\"\n</code></pre>"},{"location":"developer-guide/#registration-flow","title":"Registration Flow","text":"<pre><code>sequenceDiagram\n    participant D as @register_fetcher Decorator\n    participant R as Registry Dict\n    participant C as CLI\n\n    Note over D,C: At Import Time\n    D-&gt;&gt;R: Register \"my_source\" -&gt; MySourceFetcher\n\n    Note over D,C: At Runtime\n    C-&gt;&gt;R: get_available_sources()\n    R--&gt;&gt;C: [\"hacker_news\", \"web\", \"youtube\", \"my_source\"]\n\n    C-&gt;&gt;R: get_fetcher(\"my_source\")\n    R--&gt;&gt;C: MySourceFetcher instance</code></pre>"},{"location":"developer-guide/#customizing-llm-chains","title":"Customizing LLM Chains","text":""},{"location":"developer-guide/#modifying-prompts","title":"Modifying Prompts","text":"<p>The LangChain chains in <code>chains.py</code> use prompt templates that can be customized:</p> <pre><code># Example: Custom generator prompt\nprompt = ChatPromptTemplate.from_messages([\n    (\"system\", \"\"\"Your custom system prompt here...\n\n    Requirements:\n    - Custom requirement 1\n    - Custom requirement 2\n    \"\"\"),\n    (\"human\", \"{articles}\\n\\nGenerate {num_candidates} posts.\"),\n])\n</code></pre>"},{"location":"developer-guide/#adjusting-temperature","title":"Adjusting Temperature","text":"<p>Temperature settings affect output creativity:</p> Temperature Effect Use Case 0.0 - 0.3 Deterministic Scoring, evaluation 0.4 - 0.7 Balanced Refinement 0.8 - 1.0 Creative Content generation <pre><code>def get_llm(temperature: float = 0.7) -&gt; ChatOpenAI:\n    return ChatOpenAI(model=LLM_MODEL_NAME, temperature=temperature)\n</code></pre>"},{"location":"developer-guide/#using-different-models","title":"Using Different Models","text":"<p>Set the model via environment variable:</p> <pre><code>export OPENAI_MODEL=\"gpt-4-turbo\"  # or gpt-4o, gpt-3.5-turbo\n</code></pre>"},{"location":"developer-guide/#working-with-models","title":"Working with Models","text":""},{"location":"developer-guide/#pydantic-models","title":"Pydantic Models","text":"<p>All data structures use Pydantic for validation:</p> <pre><code>from pydantic import BaseModel, HttpUrl\nfrom typing import List, Optional\n\nclass Article(BaseModel):\n    title: str\n    url: HttpUrl\n    source: str\n    summary: str\n    topic: str\n    thumbnail: Optional[str] = None\n\n# Usage\narticle = Article(\n    title=\"My Article\",\n    url=\"https://example.com\",\n    source=\"web\",\n    summary=\"Description...\",\n    topic=\"AI\",\n)\n\n# Serialize to dict/JSON\narticle.model_dump()\narticle.model_dump_json()\n</code></pre>"},{"location":"developer-guide/#extending-models","title":"Extending Models","text":"<pre><code>class ExtendedArticle(Article):\n    \"\"\"Article with additional metadata.\"\"\"\n\n    author: Optional[str] = None\n    published_at: Optional[datetime] = None\n    read_time: Optional[int] = None\n</code></pre>"},{"location":"developer-guide/#testing","title":"Testing","text":""},{"location":"developer-guide/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest tests/ -v\n\n# Run with coverage\npytest tests/ -v --cov=ai_blogger --cov-report=html\n\n# Run specific test file\npytest tests/test_ai_blogger.py -v\n\n# Run BDD tests\npytest tests/features/ -v\n</code></pre>"},{"location":"developer-guide/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom ai_blogger import Article, get_fetcher\n\ndef test_article_validation():\n    \"\"\"Test that Article model validates correctly.\"\"\"\n    article = Article(\n        title=\"Test\",\n        url=\"https://example.com\",\n        source=\"test\",\n        summary=\"Summary\",\n        topic=\"topic\",\n    )\n    assert article.title == \"Test\"\n\ndef test_fetcher_input_validation():\n    \"\"\"Test fetcher validates inputs.\"\"\"\n    fetcher = get_fetcher(\"hacker_news\")\n\n    with pytest.raises(ValueError, match=\"Topic cannot be empty\"):\n        fetcher._validate_inputs(\"\", 5)\n</code></pre>"},{"location":"developer-guide/#bdd-testing","title":"BDD Testing","text":"<p>Feature files in <code>tests/features/</code>:</p> <pre><code>Feature: Hacker News Fetcher\n  As a content creator\n  I want to fetch articles from Hacker News\n  So that I can use them as blog source material\n\n  Scenario: Fetch articles for a topic\n    Given a Hacker News fetcher\n    When I fetch articles for topic \"AI\"\n    Then I should receive a list of articles\n</code></pre>"},{"location":"developer-guide/#code-style","title":"Code Style","text":""},{"location":"developer-guide/#formatting","title":"Formatting","text":"<p>The project uses Black and isort for formatting:</p> <pre><code># Format code\nblack ai_blogger/\nisort ai_blogger/\n\n# Check formatting\nblack --check ai_blogger/\nisort --check-only ai_blogger/\n</code></pre>"},{"location":"developer-guide/#linting","title":"Linting","text":"<pre><code># Run flake8\nflake8 ai_blogger/ --max-line-length=120\n\n# Run mypy\nmypy ai_blogger/\n</code></pre>"},{"location":"developer-guide/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>Consider adding pre-commit hooks:</p> <pre><code># .pre-commit-config.yaml\nrepos:\n  - repo: https://github.com/psf/black\n    rev: 23.12.0\n    hooks:\n      - id: black\n  - repo: https://github.com/pycqa/isort\n    rev: 5.13.0\n    hooks:\n      - id: isort\n</code></pre>"},{"location":"developer-guide/#configuration-options","title":"Configuration Options","text":""},{"location":"developer-guide/#configpy-settings","title":"config.py Settings","text":"Setting Type Description <code>TOPICS</code> List[str] Default search topics <code>SCORING_WEIGHTS</code> Dict[str, float] Criteria weights (must sum to 1.0) <code>YOUTUBE_MAX_AGE_DAYS</code> int Max age for YouTube videos <code>DEFAULT_MAX_RESULTS</code> int Default results per source <code>SOURCE_DEFAULTS</code> Dict[str, int] Per-source result counts <code>DEFAULT_NUM_CANDIDATES</code> int Number of candidates to generate <code>DEFAULT_OUTPUT_DIR</code> str Default output directory <code>LLM_MODEL_NAME</code> str OpenAI model to use"},{"location":"developer-guide/#modifying-weights","title":"Modifying Weights","text":"<pre><code># In config.py\nSCORING_WEIGHTS: Dict[str, float] = {\n    \"relevance\": 0.3,\n    \"originality\": 0.25,\n    \"depth\": 0.2,\n    \"clarity\": 0.15,\n    \"engagement\": 0.1,\n}\n\n# Weights are validated at import time\n_weights_sum = sum(SCORING_WEIGHTS.values())\nif abs(_weights_sum - 1.0) &gt; WEIGHTS_TOLERANCE:\n    raise ValueError(f\"SCORING_WEIGHTS must sum to 1.0\")\n</code></pre>"},{"location":"developer-guide/#debugging","title":"Debugging","text":""},{"location":"developer-guide/#verbose-output","title":"Verbose Output","text":"<pre><code>python -m ai_blogger --verbose\n</code></pre>"},{"location":"developer-guide/#logging-configuration","title":"Logging Configuration","text":"<pre><code>import logging\nlogging.basicConfig(level=logging.DEBUG)\n</code></pre>"},{"location":"developer-guide/#testing-individual-components","title":"Testing Individual Components","text":"<pre><code># Test a fetcher\nfrom ai_blogger import get_fetcher\n\nfetcher = get_fetcher(\"hacker_news\")\narticles = fetcher.fetch(\"AI\", 5)\nfor article in articles:\n    print(f\"- {article.title}\")\n</code></pre>"},{"location":"developer-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Error Handling: Always catch and log exceptions, return empty results on failure</li> <li>Input Validation: Use <code>_validate_inputs()</code> in fetchers</li> <li>Type Hints: Use type annotations throughout</li> <li>Documentation: Include docstrings with Args/Returns</li> <li>Testing: Write tests for new functionality</li> <li>API Keys: Never hardcode keys, use environment variables</li> </ol>"},{"location":"developer-guide/#see-also","title":"See Also","text":"<ul> <li>Architecture - System design overview</li> <li>API Reference - Module documentation</li> <li>Contributing - Contribution guidelines</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>This guide will help you get AI Blogger (Inker) up and running quickly.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before installing AI Blogger, ensure you have:</p> <ul> <li>Python 3.9 or higher</li> <li>pip (Python package manager)</li> <li>OpenAI API key (required for content generation)</li> </ul> <p>Optional API keys for extended features:</p> <ul> <li>Tavily API key for web search</li> <li>YouTube Data API v3 key for YouTube trending videos</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#from-source","title":"From Source","text":"<pre><code># Clone the repository\ngit clone https://github.com/ianlintner/inker.git\ncd inker\n\n# Create a virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install dependencies\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#as-a-package","title":"As a Package","text":"<pre><code>pip install -e .\n</code></pre>"},{"location":"getting-started/#configuration","title":"Configuration","text":""},{"location":"getting-started/#environment-variables","title":"Environment Variables","text":"<p>Set up your API keys as environment variables:</p> <pre><code># Required\nexport OPENAI_API_KEY=\"your-openai-api-key\"\n\n# Optional - for extended features\nexport TAVILY_API_KEY=\"your-tavily-api-key\"    # Web search\nexport YOUTUBE_API_KEY=\"your-youtube-api-key\"  # YouTube trending\n\n# Optional - customize the LLM model (defaults to gpt-4)\nexport OPENAI_MODEL=\"gpt-4\"  # or gpt-4-turbo, gpt-4o, gpt-3.5-turbo\n</code></pre> <p>Environment File</p> <p>Consider using a <code>.env</code> file with a tool like <code>python-dotenv</code> for local development.</p>"},{"location":"getting-started/#quick-start","title":"Quick Start","text":""},{"location":"getting-started/#basic-usage","title":"Basic Usage","text":"<p>Generate a blog post with default settings:</p> <pre><code>python -m ai_blogger\n</code></pre> <p>This will:</p> <ol> <li>Fetch articles from all available sources</li> <li>Generate 3 candidate blog posts</li> <li>Score and rank the candidates</li> <li>Refine the winning post</li> <li>Save the result to <code>./posts/</code> directory</li> </ol>"},{"location":"getting-started/#check-available-sources","title":"Check Available Sources","text":"<p>List all registered sources and their availability status:</p> <pre><code>python -m ai_blogger --list-sources\n</code></pre> <p>Output example: <pre><code>Available sources:\n  hacker_news: Fetch articles from Hacker News [\u2713]\n  web: Fetch articles from web search (Tavily) [\u2717 (missing API key)]\n  youtube: Fetch trending YouTube videos [\u2713]\n</code></pre></p>"},{"location":"getting-started/#dry-run","title":"Dry Run","text":"<p>Preview what would be done without executing:</p> <pre><code>python -m ai_blogger --dry-run\n</code></pre>"},{"location":"getting-started/#cli-options","title":"CLI Options","text":"Option Description Default <code>--num-posts N</code> Number of candidate posts to generate 3 <code>--out-dir DIR</code> Output directory for blog posts ./posts <code>--topics TOPIC...</code> Topics to search for Config defaults <code>--sources SOURCE...</code> Sources to fetch from All available <code>--max-results FORMAT</code> Max results per source Config defaults <code>--list-sources</code> List all available sources - <code>--dry-run</code> Print plan without executing False <code>-v, --verbose</code> Enable verbose output False"},{"location":"getting-started/#examples","title":"Examples","text":""},{"location":"getting-started/#custom-topics","title":"Custom Topics","text":"<pre><code>python -m ai_blogger --topics \"AI coding\" \"developer tools\"\n</code></pre>"},{"location":"getting-started/#specific-sources","title":"Specific Sources","text":"<pre><code>python -m ai_blogger --sources hacker_news youtube\n</code></pre>"},{"location":"getting-started/#custom-result-counts","title":"Custom Result Counts","text":"<pre><code>python -m ai_blogger --max-results \"hacker_news:15,youtube:10\"\n</code></pre>"},{"location":"getting-started/#generate-more-candidates","title":"Generate More Candidates","text":"<pre><code>python -m ai_blogger --num-posts 5 --out-dir ./my-posts\n</code></pre>"},{"location":"getting-started/#full-example","title":"Full Example","text":"<pre><code>python -m ai_blogger \\\n  --topics \"AI software engineering\" \"developer productivity\" \\\n  --sources hacker_news youtube \\\n  --max-results \"hacker_news:10,youtube:5\" \\\n  --num-posts 3 \\\n  --out-dir ./blog-output \\\n  --verbose\n</code></pre>"},{"location":"getting-started/#output","title":"Output","text":"<p>Blog posts are saved as Markdown files with the following format:</p> <ul> <li>Filename: <code>YYYY-MM-DD-{slugified-title}.md</code></li> <li>Location: Output directory (default: <code>./posts/</code>)</li> </ul> <p>Each file includes:</p> <ul> <li>YAML front matter with metadata (topic, score, sources)</li> <li>Full blog post content</li> <li>Author bio placeholder</li> </ul>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>Architecture Overview - Understand the system design</li> <li>Developer Guide - Learn how to extend AI Blogger</li> <li>Operations Guide - Deploy and automate AI Blogger</li> </ul>"},{"location":"operations/","title":"Operations Guide","text":"<p>This guide covers deployment, automation, monitoring, and troubleshooting for AI Blogger (Inker).</p>"},{"location":"operations/#deployment-options","title":"Deployment Options","text":""},{"location":"operations/#local-development","title":"Local Development","text":"<pre><code># Clone and setup\ngit clone https://github.com/ianlintner/inker.git\ncd inker\npython -m venv venv\nsource venv/bin/activate\npip install -r requirements.txt\n\n# Configure\nexport OPENAI_API_KEY=\"your-key\"\nexport TAVILY_API_KEY=\"your-key\"\nexport YOUTUBE_API_KEY=\"your-key\"\n\n# Run\npython -m ai_blogger\n</code></pre>"},{"location":"operations/#docker-deployment","title":"Docker Deployment","text":"<pre><code>flowchart LR\n    subgraph Container[\"Docker Container\"]\n        APP[AI Blogger]\n    end\n\n    subgraph Volumes[\"Volumes\"]\n        POSTS[/posts volume]\n    end\n\n    subgraph Secrets[\"Environment\"]\n        ENV[API Keys]\n    end\n\n    ENV --&gt; Container\n    Container --&gt; POSTS</code></pre>"},{"location":"operations/#build-and-run","title":"Build and Run","text":"<pre><code># Build the image\ndocker build -t ai-blogger .\n\n# Run with environment variables\ndocker run --rm \\\n  -e OPENAI_API_KEY=your-key \\\n  -e TAVILY_API_KEY=your-key \\\n  -e YOUTUBE_API_KEY=your-key \\\n  -v $(pwd)/posts:/app/posts \\\n  ai-blogger --num-posts 3 --out-dir /app/posts\n\n# Run with custom options\ndocker run --rm \\\n  -e OPENAI_API_KEY=your-key \\\n  -v $(pwd)/posts:/app/posts \\\n  ai-blogger \\\n  --sources hacker_news \\\n  --topics \"AI development\" \\\n  --num-posts 2 \\\n  --out-dir /app/posts\n</code></pre>"},{"location":"operations/#docker-compose","title":"Docker Compose","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  ai-blogger:\n    build: .\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      - TAVILY_API_KEY=${TAVILY_API_KEY}\n      - YOUTUBE_API_KEY=${YOUTUBE_API_KEY}\n    volumes:\n      - ./posts:/app/posts\n    command: [\"--num-posts\", \"3\", \"--out-dir\", \"/app/posts\"]\n</code></pre>"},{"location":"operations/#kubernetes-deployment","title":"Kubernetes Deployment","text":"<pre><code># ai-blogger-cronjob.yaml\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: ai-blogger\nspec:\n  schedule: \"0 6 * * *\"  # Daily at 6 AM\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n          - name: ai-blogger\n            image: ai-blogger:latest\n            args:\n              - \"--num-posts\"\n              - \"3\"\n              - \"--out-dir\"\n              - \"/app/posts\"\n            env:\n              - name: OPENAI_API_KEY\n                valueFrom:\n                  secretKeyRef:\n                    name: ai-blogger-secrets\n                    key: openai-api-key\n              - name: TAVILY_API_KEY\n                valueFrom:\n                  secretKeyRef:\n                    name: ai-blogger-secrets\n                    key: tavily-api-key\n              - name: YOUTUBE_API_KEY\n                valueFrom:\n                  secretKeyRef:\n                    name: ai-blogger-secrets\n                    key: youtube-api-key\n            volumeMounts:\n              - name: posts\n                mountPath: /app/posts\n          volumes:\n            - name: posts\n              persistentVolumeClaim:\n                claimName: ai-blogger-posts\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"operations/#automation","title":"Automation","text":""},{"location":"operations/#cron-job-setup","title":"Cron Job Setup","text":"<pre><code>flowchart LR\n    CRON[Cron Scheduler] --&gt; SCRIPT[Run Script]\n    SCRIPT --&gt; BLOGGER[AI Blogger]\n    BLOGGER --&gt; OUTPUT[Blog Posts]\n    BLOGGER --&gt; LOGS[Log Files]</code></pre>"},{"location":"operations/#basic-cron-job","title":"Basic Cron Job","text":"<pre><code># Edit crontab\ncrontab -e\n\n# Add entry to run daily at 6 AM\n0 6 * * * cd /opt/ai-blogger &amp;&amp; \\\n  /opt/ai-blogger/venv/bin/python -m ai_blogger \\\n  --num-posts 3 --out-dir ./posts \\\n  &gt;&gt; /var/log/ai-blogger.log 2&gt;&amp;1\n</code></pre>"},{"location":"operations/#advanced-cron-script","title":"Advanced Cron Script","text":"<pre><code>#!/bin/bash\n# /opt/ai-blogger/run-blogger.sh\n\nset -e\n\n# Configuration\nBLOGGER_HOME=\"/opt/ai-blogger\"\nVENV_PATH=\"$BLOGGER_HOME/venv\"\nOUTPUT_DIR=\"$BLOGGER_HOME/posts\"\nLOG_FILE=\"$BLOGGER_HOME/logs/ai-blogger-$(date +%Y-%m-%d).log\"\n\n# Load environment\nsource \"$VENV_PATH/bin/activate\"\nsource \"$BLOGGER_HOME/.env\"\n\n# Create log directory\nmkdir -p \"$(dirname \"$LOG_FILE\")\"\n\n# Run AI Blogger\necho \"=== Starting AI Blogger at $(date) ===\" &gt;&gt; \"$LOG_FILE\"\n\npython -m ai_blogger \\\n  --num-posts 3 \\\n  --out-dir \"$OUTPUT_DIR\" \\\n  --verbose \\\n  &gt;&gt; \"$LOG_FILE\" 2&gt;&amp;1\n\nSTATUS=$?\n\nif [ $STATUS -eq 0 ]; then\n    echo \"=== Completed successfully at $(date) ===\" &gt;&gt; \"$LOG_FILE\"\nelse\n    echo \"=== Failed with status $STATUS at $(date) ===\" &gt;&gt; \"$LOG_FILE\"\n    # Optional: Send notification\n    # curl -X POST \"$SLACK_WEBHOOK\" -d '{\"text\":\"AI Blogger failed\"}'\nfi\n\nexit $STATUS\n</code></pre>"},{"location":"operations/#systemd-timer","title":"Systemd Timer","text":"<pre><code># /etc/systemd/system/ai-blogger.service\n[Unit]\nDescription=AI Blogger Daily Run\nAfter=network-online.target\n\n[Service]\nType=oneshot\nUser=blogger\nWorkingDirectory=/opt/ai-blogger\nEnvironment=\"PATH=/opt/ai-blogger/venv/bin\"\nEnvironmentFile=/opt/ai-blogger/.env\nExecStart=/opt/ai-blogger/venv/bin/python -m ai_blogger --num-posts 3 --out-dir /opt/ai-blogger/posts\nStandardOutput=append:/var/log/ai-blogger/output.log\nStandardError=append:/var/log/ai-blogger/error.log\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <pre><code># /etc/systemd/system/ai-blogger.timer\n[Unit]\nDescription=Run AI Blogger daily\n\n[Timer]\nOnCalendar=*-*-* 06:00:00\nPersistent=true\n\n[Install]\nWantedBy=timers.target\n</code></pre> <pre><code># Enable and start\nsudo systemctl enable ai-blogger.timer\nsudo systemctl start ai-blogger.timer\n\n# Check status\nsudo systemctl status ai-blogger.timer\nsudo systemctl list-timers\n</code></pre>"},{"location":"operations/#monitoring","title":"Monitoring","text":""},{"location":"operations/#health-checks","title":"Health Checks","text":"<pre><code>flowchart TB\n    subgraph Checks[\"Health Checks\"]\n        API[API Availability]\n        DISK[Disk Space]\n        QUOTA[API Quotas]\n        OUTPUT[Output Files]\n    end\n\n    subgraph Actions[\"Actions\"]\n        ALERT[Send Alert]\n        LOG[Log Status]\n    end\n\n    Checks --&gt; LOG\n    Checks --&gt;|Failure| ALERT</code></pre>"},{"location":"operations/#check-script","title":"Check Script","text":"<pre><code>#!/bin/bash\n# /opt/ai-blogger/health-check.sh\n\n# Check OpenAI API\ncheck_openai() {\n    response=$(curl -s -o /dev/null -w \"%{http_code}\" \\\n        -H \"Authorization: Bearer $OPENAI_API_KEY\" \\\n        \"https://api.openai.com/v1/models\")\n    [ \"$response\" = \"200\" ]\n}\n\n# Check YouTube API\ncheck_youtube() {\n    response=$(curl -s -o /dev/null -w \"%{http_code}\" \\\n        \"https://www.googleapis.com/youtube/v3/search?key=$YOUTUBE_API_KEY&amp;part=snippet&amp;maxResults=1&amp;q=test\")\n    [ \"$response\" = \"200\" ]\n}\n\n# Check disk space\ncheck_disk() {\n    available=$(df -BG /opt/ai-blogger/posts | awk 'NR==2 {print $4}' | sed 's/G//')\n    [ \"$available\" -gt 1 ]  # At least 1GB free\n}\n\n# Run checks\necho \"Running health checks...\"\n\nif check_openai; then\n    echo \"\u2713 OpenAI API: OK\"\nelse\n    echo \"\u2717 OpenAI API: FAILED\"\nfi\n\nif check_youtube; then\n    echo \"\u2713 YouTube API: OK\"\nelse\n    echo \"\u2717 YouTube API: FAILED\"\nfi\n\nif check_disk; then\n    echo \"\u2713 Disk Space: OK\"\nelse\n    echo \"\u2717 Disk Space: LOW\"\nfi\n</code></pre>"},{"location":"operations/#logging","title":"Logging","text":""},{"location":"operations/#log-rotation","title":"Log Rotation","text":"<pre><code># /etc/logrotate.d/ai-blogger\n/var/log/ai-blogger/*.log {\n    daily\n    missingok\n    rotate 14\n    compress\n    delaycompress\n    notifempty\n    create 0644 blogger blogger\n}\n</code></pre>"},{"location":"operations/#structured-logging","title":"Structured Logging","text":"<pre><code>import logging\nimport json\nfrom datetime import datetime\n\nclass JSONFormatter(logging.Formatter):\n    def format(self, record):\n        return json.dumps({\n            \"timestamp\": datetime.utcnow().isoformat(),\n            \"level\": record.levelname,\n            \"message\": record.getMessage(),\n            \"module\": record.module,\n        })\n\n# Configure\nhandler = logging.StreamHandler()\nhandler.setFormatter(JSONFormatter())\nlogging.getLogger().addHandler(handler)\n</code></pre>"},{"location":"operations/#metrics","title":"Metrics","text":"<p>Track key metrics for monitoring:</p> Metric Description Alert Threshold <code>articles_fetched</code> Total articles fetched &lt; 10 per run <code>candidates_generated</code> Blog candidates created &lt; requested <code>run_duration</code> Total execution time &gt; 10 minutes <code>api_errors</code> API call failures &gt; 0 <code>disk_usage</code> Output directory size &gt; 90%"},{"location":"operations/#api-rate-limits","title":"API Rate Limits","text":""},{"location":"operations/#youtube-data-api","title":"YouTube Data API","text":"<pre><code>flowchart LR\n    QUOTA[10,000 units/day] --&gt; SEARCH[Search: 100 units]\n    QUOTA --&gt; VIDEO[Video details: 1 unit]\n\n    TOPICS[9 topics] --&gt; CALLS[9 API calls]\n    CALLS --&gt; USAGE[900 units/run]</code></pre> <ul> <li>Default quota: 10,000 units/day</li> <li>Search request: 100 units</li> <li>With 9 topics: ~900 units per run</li> <li>Maximum safe runs: ~10/day</li> </ul>"},{"location":"operations/#openai-api","title":"OpenAI API","text":"<ul> <li>Rate limits vary by tier</li> <li>Monitor usage in OpenAI dashboard</li> <li>Consider using <code>gpt-3.5-turbo</code> for lower costs</li> </ul>"},{"location":"operations/#tavily-api","title":"Tavily API","text":"<ul> <li>Check your plan limits</li> <li>Default is typically 1,000 searches/month</li> </ul>"},{"location":"operations/#troubleshooting","title":"Troubleshooting","text":""},{"location":"operations/#common-issues","title":"Common Issues","text":""},{"location":"operations/#no-articles-found","title":"No Articles Found","text":"<pre><code>Error: No articles found.\n</code></pre> <p>Causes:</p> <ol> <li>Missing API keys</li> <li>Network connectivity issues</li> <li>No results for topics</li> </ol> <p>Solutions:</p> <pre><code># Check API key availability\npython -m ai_blogger --list-sources\n\n# Verify network\ncurl -s \"https://hn.algolia.com/api/v1/search?query=test\"\n\n# Try with verbose output\npython -m ai_blogger --verbose\n</code></pre>"},{"location":"operations/#api-key-issues","title":"API Key Issues","text":"<pre><code>Warning: YOUTUBE_API_KEY not set - YouTube trending will be disabled\n</code></pre> <p>Solutions:</p> <pre><code># Verify environment variable\necho $YOUTUBE_API_KEY\n\n# Test API directly\ncurl \"https://www.googleapis.com/youtube/v3/search?key=$YOUTUBE_API_KEY&amp;part=snippet&amp;maxResults=1&amp;q=test\"\n</code></pre>"},{"location":"operations/#llm-parsing-errors","title":"LLM Parsing Errors","text":"<pre><code>Error parsing candidate posts: JSONDecodeError\n</code></pre> <p>Causes:</p> <ol> <li>API rate limiting</li> <li>Model response issues</li> <li>Network timeouts</li> </ol> <p>Solutions:</p> <pre><code># Try with different model\nexport OPENAI_MODEL=\"gpt-3.5-turbo\"\n\n# Run with fewer candidates\npython -m ai_blogger --num-posts 2\n</code></pre>"},{"location":"operations/#disk-space-issues","title":"Disk Space Issues","text":"<pre><code># Check available space\ndf -h /opt/ai-blogger/posts\n\n# Clean old posts\nfind /opt/ai-blogger/posts -name \"*.md\" -mtime +30 -delete\n</code></pre>"},{"location":"operations/#debug-mode","title":"Debug Mode","text":"<pre><code># Enable verbose logging\npython -m ai_blogger --verbose\n\n# Python debug mode\npython -v -m ai_blogger\n\n# Full debug with logging\nPYTHONPATH=. python -c \"\nimport logging\nlogging.basicConfig(level=logging.DEBUG)\nfrom ai_blogger import get_fetcher\nfetcher = get_fetcher('hacker_news')\narticles = fetcher.fetch('AI', 5)\nprint(f'Found {len(articles)} articles')\n\"\n</code></pre>"},{"location":"operations/#log-analysis","title":"Log Analysis","text":"<pre><code># Check recent logs\ntail -f /var/log/ai-blogger.log\n\n# Search for errors\ngrep -i error /var/log/ai-blogger.log | tail -20\n\n# Count runs by status\ngrep \"SUCCESS\\|FAILED\" /var/log/ai-blogger.log | sort | uniq -c\n</code></pre>"},{"location":"operations/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"operations/#backup-strategy","title":"Backup Strategy","text":"<pre><code>#!/bin/bash\n# backup-posts.sh\n\nBACKUP_DIR=\"/backup/ai-blogger\"\nPOSTS_DIR=\"/opt/ai-blogger/posts\"\nDATE=$(date +%Y-%m-%d)\n\n# Create backup\ntar -czf \"$BACKUP_DIR/posts-$DATE.tar.gz\" -C \"$POSTS_DIR\" .\n\n# Clean old backups (keep 30 days)\nfind \"$BACKUP_DIR\" -name \"*.tar.gz\" -mtime +30 -delete\n</code></pre>"},{"location":"operations/#recovery","title":"Recovery","text":"<pre><code># Restore from backup\ntar -xzf /backup/ai-blogger/posts-2024-01-15.tar.gz -C /opt/ai-blogger/posts\n</code></pre>"},{"location":"operations/#security-considerations","title":"Security Considerations","text":""},{"location":"operations/#api-key-protection","title":"API Key Protection","text":"<ul> <li>Never commit API keys to source control</li> <li>Use environment files with restricted permissions</li> <li>Consider using secret management solutions (Vault, AWS Secrets Manager)</li> </ul> <pre><code># Secure .env file\nchmod 600 /opt/ai-blogger/.env\nchown blogger:blogger /opt/ai-blogger/.env\n</code></pre>"},{"location":"operations/#container-security","title":"Container Security","text":"<ul> <li>Run as non-root user</li> <li>Use read-only filesystem where possible</li> <li>Limit container capabilities</li> </ul> <pre><code>USER appuser\n</code></pre>"},{"location":"operations/#see-also","title":"See Also","text":"<ul> <li>Architecture - System design overview</li> <li>Developer Guide - Extension guide</li> <li>Getting Started - Quick start guide</li> </ul>"},{"location":"persistence/","title":"Persistence Layer","text":"<p>This document describes the modular persistence layer for storing jobs, blog posts, approval status, and historical statistics.</p>"},{"location":"persistence/#overview","title":"Overview","text":"<p>The persistence layer provides a unified storage interface with support for multiple backends:</p> <ul> <li>SQLite: Default file-based storage for local development and simple deployments</li> <li>PostgreSQL: Production-ready storage for scalable deployments</li> <li>Vector Storage: Extensible architecture for future vector database support</li> </ul> <pre><code>flowchart TB\n    subgraph Application[\"Application Layer\"]\n        JOB[JobService]\n        API[REST API]\n    end\n\n    subgraph Storage[\"Storage Layer\"]\n        FACTORY[create_storage]\n        BASE[StorageBackend]\n        SQLITE[SQLiteStorage]\n        PG[PostgresStorage]\n        VECTOR[VectorStorage...]\n    end\n\n    subgraph Data[\"Data Layer\"]\n        SQLITE_DB[(SQLite File)]\n        PG_DB[(PostgreSQL)]\n        VEC_DB[(Vector DB)]\n    end\n\n    JOB &amp; API --&gt; FACTORY\n    FACTORY --&gt; BASE\n    BASE --&gt; SQLITE &amp; PG &amp; VECTOR\n    SQLITE --&gt; SQLITE_DB\n    PG --&gt; PG_DB\n    VECTOR --&gt; VEC_DB</code></pre>"},{"location":"persistence/#quick-start","title":"Quick Start","text":""},{"location":"persistence/#basic-usage","title":"Basic Usage","text":"<pre><code>from ai_blogger.persistence import create_storage, BlogPostCreate\n\n# Auto-detect storage based on environment\nstorage = create_storage()\n\n# Create a blog post\npost = storage.create_post(BlogPostCreate(\n    title=\"Introduction to AI\",\n    content=\"# AI Basics\\n\\nAI is transforming...\",\n    topic=\"AI development\",\n    sources=[\"https://example.com\"],\n    job_id=\"job-123\",\n))\n\n# Approve the post\nstorage.approve_post(post.id, feedback=\"Excellent content!\")\n\n# Publish the post\nstorage.publish_post(post.id)\n</code></pre>"},{"location":"persistence/#environment-configuration","title":"Environment Configuration","text":"<pre><code># Use PostgreSQL (production)\nexport DATABASE_URL=\"postgresql://user:pass@localhost/inker\"\n\n# Use SQLite (development, default)\nexport INKER_DB_PATH=\"./data/inker.db\"\n</code></pre>"},{"location":"persistence/#storage-models","title":"Storage Models","text":""},{"location":"persistence/#blogpost","title":"BlogPost","text":"<p>The primary model for storing blog posts with full lifecycle tracking.</p> <pre><code>class BlogPost(BaseModel):\n    id: str                           # Unique identifier\n    title: str                        # Blog post title\n    content: str                      # Full markdown content\n    word_count: int                   # Word count\n    topic: str                        # Main topic\n    sources: List[str]                # Source URLs\n    job_id: Optional[str]             # Associated job ID\n    approval_status: ApprovalStatus   # Current approval state\n    approval_feedback: Optional[str]  # Reviewer feedback\n    scoring: Optional[Dict]           # Scoring data\n    metadata: Optional[Dict]          # Additional data\n    created_at: datetime              # Creation time\n    updated_at: datetime              # Last update time\n    approved_at: Optional[datetime]   # Approval time\n    published_at: Optional[datetime]  # Publication time\n</code></pre>"},{"location":"persistence/#approvalstatus","title":"ApprovalStatus","text":"<p>Blog post approval workflow states:</p> Status Description <code>PENDING</code> Awaiting review <code>APPROVED</code> Approved for publication <code>REJECTED</code> Rejected, will not be published <code>REVISION_REQUESTED</code> Needs revision before approval"},{"location":"persistence/#jobhistoryentry","title":"JobHistoryEntry","text":"<p>Tracks all actions on jobs and posts for audit trail.</p> <pre><code>class JobHistoryEntry(BaseModel):\n    id: str                           # Entry ID\n    job_id: str                       # Related job\n    post_id: Optional[str]            # Related post\n    action: str                       # Action type\n    previous_status: Optional[str]    # Previous state\n    new_status: Optional[str]         # New state\n    actor: Optional[str]              # Who performed action\n    feedback: Optional[str]           # Action feedback\n    metadata: Optional[Dict]          # Additional data\n    created_at: datetime              # When action occurred\n</code></pre>"},{"location":"persistence/#jobstats","title":"JobStats","text":"<p>Aggregated statistics for monitoring and reporting.</p> <pre><code>class JobStats(BaseModel):\n    total_jobs: int\n    pending_jobs: int\n    completed_jobs: int\n    failed_jobs: int\n    total_posts: int\n    pending_approval: int\n    approved_posts: int\n    rejected_posts: int\n    revision_requested: int\n    published_posts: int\n    avg_approval_time_hours: Optional[float]\n    approval_rate: Optional[float]\n</code></pre>"},{"location":"persistence/#api-contract","title":"API Contract","text":"<p>The <code>StorageBackend</code> abstract base class defines the contract for all storage implementations:</p>"},{"location":"persistence/#blog-post-operations","title":"Blog Post Operations","text":"<pre><code>class StorageBackend(ABC):\n    def create_post(self, post: BlogPostCreate) -&gt; BlogPost: ...\n    def get_post(self, post_id: str) -&gt; Optional[BlogPost]: ...\n    def get_post_by_job_id(self, job_id: str) -&gt; Optional[BlogPost]: ...\n    def update_post(self, post_id: str, update: BlogPostUpdate) -&gt; Optional[BlogPost]: ...\n    def delete_post(self, post_id: str) -&gt; bool: ...\n    def list_posts(\n        self,\n        approval_status: Optional[ApprovalStatus] = None,\n        topic: Optional[str] = None,\n        limit: int = 100,\n        offset: int = 0,\n    ) -&gt; List[BlogPost]: ...\n</code></pre>"},{"location":"persistence/#approval-workflow","title":"Approval Workflow","text":"<pre><code>def approve_post(\n    self, post_id: str, feedback: Optional[str] = None, actor: Optional[str] = None\n) -&gt; Optional[BlogPost]: ...\n\ndef reject_post(\n    self, post_id: str, feedback: str, actor: Optional[str] = None\n) -&gt; Optional[BlogPost]: ...\n\ndef request_revision(\n    self, post_id: str, feedback: str, actor: Optional[str] = None\n) -&gt; Optional[BlogPost]: ...\n\ndef publish_post(self, post_id: str) -&gt; Optional[BlogPost]: ...\n</code></pre>"},{"location":"persistence/#history-tracking","title":"History Tracking","text":"<pre><code>def add_history_entry(\n    self,\n    job_id: str,\n    action: str,\n    post_id: Optional[str] = None,\n    previous_status: Optional[str] = None,\n    new_status: Optional[str] = None,\n    actor: Optional[str] = None,\n    feedback: Optional[str] = None,\n    metadata: Optional[Dict[str, Any]] = None,\n) -&gt; JobHistoryEntry: ...\n\ndef get_job_history(self, job_id: str) -&gt; List[JobHistoryEntry]: ...\ndef get_post_history(self, post_id: str) -&gt; List[JobHistoryEntry]: ...\n</code></pre>"},{"location":"persistence/#statistics-health","title":"Statistics &amp; Health","text":"<pre><code>def get_stats(self) -&gt; JobStats: ...\ndef health_check(self) -&gt; bool: ...\n</code></pre>"},{"location":"persistence/#storage-backends","title":"Storage Backends","text":""},{"location":"persistence/#sqlite-default","title":"SQLite (Default)","text":"<p>File-based storage, ideal for development and simple deployments.</p> <pre><code>from ai_blogger.persistence import create_storage\n\n# Explicit configuration\nstorage = create_storage(\n    backend_type=\"sqlite\",\n    db_path=\"./data/inker.db\",\n)\n\n# Or via environment\n# export INKER_DB_PATH=\"./data/inker.db\"\nstorage = create_storage()\n</code></pre> <p>Features: - Thread-safe with connection pooling - Auto-migration on initialization - No external dependencies</p>"},{"location":"persistence/#postgresql","title":"PostgreSQL","text":"<p>Production-ready storage with connection pooling.</p> <pre><code>from ai_blogger.persistence import create_storage\n\n# Explicit configuration\nstorage = create_storage(\n    backend_type=\"postgres\",\n    connection_string=\"postgresql://user:pass@localhost/inker\",\n    pool_size=10,\n)\n\n# Or via environment\n# export DATABASE_URL=\"postgresql://user:pass@localhost/inker\"\nstorage = create_storage()\n</code></pre> <p>Features: - Connection pooling - Native JSONB support - Enum types for approval status - Efficient indexing</p> <p>Requirements: <pre><code>pip install psycopg2-binary\n</code></pre></p>"},{"location":"persistence/#database-schema","title":"Database Schema","text":""},{"location":"persistence/#blog_posts-table","title":"blog_posts Table","text":"Column Type Description id UUID/TEXT Primary key title TEXT Post title content TEXT Full content word_count INTEGER Word count topic TEXT Main topic sources JSONB/TEXT Source URLs (JSON) job_id TEXT Related job ID approval_status ENUM/TEXT Current status approval_feedback TEXT Reviewer feedback scoring JSONB/TEXT Scoring data metadata JSONB/TEXT Additional data created_at TIMESTAMP Creation time updated_at TIMESTAMP Last update approved_at TIMESTAMP Approval time published_at TIMESTAMP Publication time"},{"location":"persistence/#job_history-table","title":"job_history Table","text":"Column Type Description id UUID/TEXT Primary key job_id TEXT Related job post_id UUID/TEXT Related post action TEXT Action type previous_status TEXT Previous state new_status TEXT New state actor TEXT Who performed feedback TEXT Action notes metadata JSONB/TEXT Additional data created_at TIMESTAMP When occurred"},{"location":"persistence/#migrations","title":"Migrations","text":"<p>Both backends support auto-migration via the <code>auto_migrate</code> config option (default: <code>True</code>).</p>"},{"location":"persistence/#schema-versioning","title":"Schema Versioning","text":"<pre><code># Check/run migrations manually\nfrom ai_blogger.persistence import SQLiteStorage, StorageConfig\n\nconfig = StorageConfig(\n    backend_type=\"sqlite\",\n    db_path=\"./data/inker.db\",\n    auto_migrate=False,  # Don't auto-migrate\n)\nstorage = SQLiteStorage(config)\n\n# Manual initialization\nstorage.initialize()\n</code></pre> <p>Migrations are tracked in the <code>schema_version</code> table.</p>"},{"location":"persistence/#extending-storage","title":"Extending Storage","text":"<p>To add a new storage backend:</p> <ol> <li>Create a new class that inherits from <code>StorageBackend</code></li> <li>Implement all abstract methods</li> <li>Register in the factory</li> </ol> <pre><code>from ai_blogger.persistence import StorageBackend, StorageConfig\n\nclass VectorStorage(StorageBackend):\n    \"\"\"Vector database storage backend.\"\"\"\n\n    def __init__(self, config: StorageConfig):\n        self.config = config\n        # Initialize vector DB connection\n\n    def initialize(self) -&gt; None:\n        # Create collections/indexes\n        pass\n\n    def create_post(self, post: BlogPostCreate) -&gt; BlogPost:\n        # Store post with embeddings\n        pass\n\n    # ... implement remaining methods\n</code></pre>"},{"location":"persistence/#example-workflows","title":"Example Workflows","text":""},{"location":"persistence/#blog-post-lifecycle","title":"Blog Post Lifecycle","text":"<pre><code>from ai_blogger.persistence import create_storage, BlogPostCreate, ApprovalStatus\n\nstorage = create_storage()\n\n# 1. Create post from job result\npost = storage.create_post(BlogPostCreate(\n    title=\"AI Trends 2024\",\n    content=\"# AI Trends\\n\\n...\",\n    topic=\"AI development\",\n    job_id=\"job-abc123\",\n    scoring={\"total\": 8.5, \"relevance\": 9.0},\n))\n\n# 2. Review workflow\nstorage.request_revision(post.id, \"Please add more examples\", actor=\"reviewer-1\")\n\n# 3. Update post\nstorage.update_post(post.id, BlogPostUpdate(\n    content=\"# AI Trends\\n\\n(Updated with examples)...\"\n))\n\n# 4. Approve\nstorage.approve_post(post.id, feedback=\"Excellent revision!\", actor=\"reviewer-1\")\n\n# 5. Publish\nstorage.publish_post(post.id)\n\n# 6. View history\nhistory = storage.get_post_history(post.id)\nfor entry in history:\n    print(f\"{entry.action}: {entry.feedback}\")\n</code></pre>"},{"location":"persistence/#monitoring-statistics","title":"Monitoring Statistics","text":"<pre><code>from ai_blogger.persistence import create_storage\n\nstorage = create_storage()\nstats = storage.get_stats()\n\nprint(f\"Total posts: {stats.total_posts}\")\nprint(f\"Pending approval: {stats.pending_approval}\")\nif stats.approval_rate is not None:\n    print(f\"Approval rate: {stats.approval_rate:.1f}%\")\nelse:\n    print(\"Approval rate: N/A\")\nif stats.avg_approval_time_hours is not None:\n    print(f\"Avg approval time: {stats.avg_approval_time_hours:.1f} hours\")\nelse:\n    print(\"Avg approval time: N/A\")\n</code></pre>"},{"location":"persistence/#see-also","title":"See Also","text":"<ul> <li>Architecture - System design overview</li> <li>API Reference - Detailed module documentation (including Feedback API)</li> <li>Developer Guide - Extension guide</li> </ul>"}]}